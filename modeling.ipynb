{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# libraries\nimport keras\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pylab as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read csv\ndf = pd.read_csv('../input/dhanvarsha/Interview_round_dataset.csv') ","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check dataframe\ndf.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"    Sr_No  Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n0   26791  -1.101444   0.780847  -0.150606   0.044194   2.779388   3.826857   \n1   91547   0.905274   0.080784   1.547836   2.570243  -0.100630   2.017006   \n2  281304   2.021258   0.153611  -1.710915   1.198175   0.602164  -0.652300   \n3   83873   1.191927  -0.039543   0.537142   0.697681  -0.402698  -0.052089   \n4  252334   0.121001   1.015667  -0.404468  -0.539553   0.988905  -0.848640   \n\n   Feature_7  Feature_8  Feature_9  ...  Feature_21  Feature_22  Feature_23  \\\n0   0.505011   0.448779   0.428350  ...   -0.318102   -0.110152   -0.045112   \n1  -0.840341   0.709949  -0.016073  ...    0.064652    0.504713    0.201644   \n2   0.488583  -0.218795   0.048074  ...    0.069765    0.385032   -0.042500   \n3  -0.224193   0.045363   0.317585  ...   -0.069138    0.024003   -0.133153   \n4   0.959057  -0.120624  -0.082330  ...   -0.337542   -0.819971    0.094267   \n\n   Feature_24  Feature_25  Feature_26  Feature_27  Feature_28  Feature_29  \\\n0    1.008263    0.237554   -0.296286    0.072267   -0.072137       20.13   \n1   -0.618860   -0.043392    0.062233    0.117348    0.026562        6.08   \n2   -0.405255    0.455746   -0.484028   -0.021226   -0.077854        1.99   \n3    0.087927    0.580386    0.411193   -0.015511    0.000913       12.31   \n4    0.566302   -0.407398    0.112873    0.223010    0.085447        1.79   \n\n   Target_flag  \n0            0  \n1            0  \n2            0  \n3            0  \n4            0  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sr_No</th>\n      <th>Feature_1</th>\n      <th>Feature_2</th>\n      <th>Feature_3</th>\n      <th>Feature_4</th>\n      <th>Feature_5</th>\n      <th>Feature_6</th>\n      <th>Feature_7</th>\n      <th>Feature_8</th>\n      <th>Feature_9</th>\n      <th>...</th>\n      <th>Feature_21</th>\n      <th>Feature_22</th>\n      <th>Feature_23</th>\n      <th>Feature_24</th>\n      <th>Feature_25</th>\n      <th>Feature_26</th>\n      <th>Feature_27</th>\n      <th>Feature_28</th>\n      <th>Feature_29</th>\n      <th>Target_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>26791</td>\n      <td>-1.101444</td>\n      <td>0.780847</td>\n      <td>-0.150606</td>\n      <td>0.044194</td>\n      <td>2.779388</td>\n      <td>3.826857</td>\n      <td>0.505011</td>\n      <td>0.448779</td>\n      <td>0.428350</td>\n      <td>...</td>\n      <td>-0.318102</td>\n      <td>-0.110152</td>\n      <td>-0.045112</td>\n      <td>1.008263</td>\n      <td>0.237554</td>\n      <td>-0.296286</td>\n      <td>0.072267</td>\n      <td>-0.072137</td>\n      <td>20.13</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>91547</td>\n      <td>0.905274</td>\n      <td>0.080784</td>\n      <td>1.547836</td>\n      <td>2.570243</td>\n      <td>-0.100630</td>\n      <td>2.017006</td>\n      <td>-0.840341</td>\n      <td>0.709949</td>\n      <td>-0.016073</td>\n      <td>...</td>\n      <td>0.064652</td>\n      <td>0.504713</td>\n      <td>0.201644</td>\n      <td>-0.618860</td>\n      <td>-0.043392</td>\n      <td>0.062233</td>\n      <td>0.117348</td>\n      <td>0.026562</td>\n      <td>6.08</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>281304</td>\n      <td>2.021258</td>\n      <td>0.153611</td>\n      <td>-1.710915</td>\n      <td>1.198175</td>\n      <td>0.602164</td>\n      <td>-0.652300</td>\n      <td>0.488583</td>\n      <td>-0.218795</td>\n      <td>0.048074</td>\n      <td>...</td>\n      <td>0.069765</td>\n      <td>0.385032</td>\n      <td>-0.042500</td>\n      <td>-0.405255</td>\n      <td>0.455746</td>\n      <td>-0.484028</td>\n      <td>-0.021226</td>\n      <td>-0.077854</td>\n      <td>1.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>83873</td>\n      <td>1.191927</td>\n      <td>-0.039543</td>\n      <td>0.537142</td>\n      <td>0.697681</td>\n      <td>-0.402698</td>\n      <td>-0.052089</td>\n      <td>-0.224193</td>\n      <td>0.045363</td>\n      <td>0.317585</td>\n      <td>...</td>\n      <td>-0.069138</td>\n      <td>0.024003</td>\n      <td>-0.133153</td>\n      <td>0.087927</td>\n      <td>0.580386</td>\n      <td>0.411193</td>\n      <td>-0.015511</td>\n      <td>0.000913</td>\n      <td>12.31</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>252334</td>\n      <td>0.121001</td>\n      <td>1.015667</td>\n      <td>-0.404468</td>\n      <td>-0.539553</td>\n      <td>0.988905</td>\n      <td>-0.848640</td>\n      <td>0.959057</td>\n      <td>-0.120624</td>\n      <td>-0.082330</td>\n      <td>...</td>\n      <td>-0.337542</td>\n      <td>-0.819971</td>\n      <td>0.094267</td>\n      <td>0.566302</td>\n      <td>-0.407398</td>\n      <td>0.112873</td>\n      <td>0.223010</td>\n      <td>0.085447</td>\n      <td>1.79</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 31 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check shape of dataframe\ndf.shape","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"(227198, 31)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check columns of dataframe\ndf.columns","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"Index(['Sr_No', 'Feature_1', 'Feature_2', 'Feature_3', 'Feature_4',\n       'Feature_5', 'Feature_6', 'Feature_7', 'Feature_8', 'Feature_9',\n       'Feature_10', 'Feature_11', 'Feature_12', 'Feature_13', 'Feature_14',\n       'Feature_15', 'Feature_16', 'Feature_17', 'Feature_18', 'Feature_19',\n       'Feature_20', 'Feature_21', 'Feature_22', 'Feature_23', 'Feature_24',\n       'Feature_25', 'Feature_26', 'Feature_27', 'Feature_28', 'Feature_29',\n       'Target_flag'],\n      dtype='object')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check info of dataframe\ndf.info()","execution_count":6,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 227198 entries, 0 to 227197\nData columns (total 31 columns):\n #   Column       Non-Null Count   Dtype  \n---  ------       --------------   -----  \n 0   Sr_No        227198 non-null  int64  \n 1   Feature_1    227198 non-null  float64\n 2   Feature_2    227198 non-null  float64\n 3   Feature_3    227198 non-null  float64\n 4   Feature_4    227198 non-null  float64\n 5   Feature_5    227198 non-null  float64\n 6   Feature_6    227198 non-null  float64\n 7   Feature_7    227198 non-null  float64\n 8   Feature_8    227198 non-null  float64\n 9   Feature_9    227198 non-null  float64\n 10  Feature_10   227198 non-null  float64\n 11  Feature_11   227198 non-null  float64\n 12  Feature_12   227198 non-null  float64\n 13  Feature_13   227198 non-null  float64\n 14  Feature_14   227198 non-null  float64\n 15  Feature_15   227198 non-null  float64\n 16  Feature_16   227198 non-null  float64\n 17  Feature_17   227198 non-null  float64\n 18  Feature_18   227198 non-null  float64\n 19  Feature_19   227198 non-null  float64\n 20  Feature_20   227198 non-null  float64\n 21  Feature_21   227198 non-null  float64\n 22  Feature_22   227198 non-null  float64\n 23  Feature_23   227198 non-null  float64\n 24  Feature_24   227198 non-null  float64\n 25  Feature_25   227198 non-null  float64\n 26  Feature_26   227198 non-null  float64\n 27  Feature_27   227198 non-null  float64\n 28  Feature_28   227198 non-null  float64\n 29  Feature_29   227198 non-null  float64\n 30  Target_flag  227198 non-null  int64  \ndtypes: float64(29), int64(2)\nmemory usage: 53.7 MB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check number of unique values in each column\ndf.nunique(axis=0)","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"Sr_No          227198\nFeature_1      220792\nFeature_2      220792\nFeature_3      220792\nFeature_4      220794\nFeature_5      220794\nFeature_6      220790\nFeature_7      220791\nFeature_8      220784\nFeature_9      220793\nFeature_10     220785\nFeature_11     220787\nFeature_12     220791\nFeature_13     220795\nFeature_14     220792\nFeature_15     220791\nFeature_16     220785\nFeature_17     220785\nFeature_18     220792\nFeature_19     220790\nFeature_20     220778\nFeature_21     220768\nFeature_22     220787\nFeature_23     220770\nFeature_24     220789\nFeature_25     220785\nFeature_26     220786\nFeature_27     220756\nFeature_28     220721\nFeature_29      29283\nTarget_flag         2\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check target variable distribution\ndf['Target_flag'].value_counts()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"0    226806\n1       392\nName: Target_flag, dtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"As seen from this cell, the dataset is highly imbalanced. While working on an imbalanced dataset accuracy is not an appropriate measure to evaluate model performance. For eg: A classifier which achieves an accuracy of 98 % with an event rate of 2 % is not accurate, if it classifies all instances as the majority class. And eliminates the 2 % minority class observations as noise."},{"metadata":{},"cell_type":"markdown","source":"# Baseline Model"},{"metadata":{},"cell_type":"markdown","source":"We start by creating a base model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# seperate the features and target variables\nlabels = df.columns[1:30]\nX = df[labels]\ny = df['Target_flag']\n\n# create train-test split with stratify  \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=7, stratify=y)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check shape of created train-test split\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","execution_count":10,"outputs":[{"output_type":"stream","text":"(204478, 29)\n(204478,)\n(22720, 29)\n(22720,)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define the different metrics we will be using\nmetrics = [\n      keras.metrics.TruePositives(name='tp'),\n      keras.metrics.FalsePositives(name='fp'),\n      keras.metrics.TrueNegatives(name='tn'),\n      keras.metrics.FalseNegatives(name='fn'),\n      keras.metrics.BinaryAccuracy(name='accuracy'),\n      keras.metrics.Precision(name='precision'),\n      keras.metrics.Recall(name='recall'),\n      keras.metrics.AUC(name='auc'),\n]\n\n# define batch size\nbatch_size = 2048","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In general, you should strive for a small batch size (e.g. 32). Our case is a bit specific, we have highly imbalanced data, so weâ€™ll give a fair chance to each batch before the weights are updated."},{"metadata":{"trusted":true},"cell_type":"code","source":"# define our model\ndef build_model(train_data, metrics=metrics):\n    \n    model = keras.Sequential([\n    keras.layers.Dense(units=29,activation='relu',input_shape=(train_data.shape[-1],)),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.25),\n    keras.layers.Dense(units=29,activation='relu'),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.25),\n    keras.layers.Dense(units=29,activation='relu'),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.25),\n    keras.layers.Dense(units=1, activation='sigmoid'),\n    ])\n    \n    # compile our model\n    model.compile(\n    optimizer=keras.optimizers.Adam(lr=0.001),\n    loss=keras.losses.BinaryCrossentropy(),\n    metrics=metrics\n    )\n\n    return model","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training the model\nmodel = build_model(X_train)\nhistory = model.fit(\n    X_train,\n    y_train,\n    batch_size=batch_size,\n    epochs=20,\n    validation_split=0.05,\n    shuffle=True,\n    verbose=1\n)","execution_count":13,"outputs":[{"output_type":"stream","text":"Epoch 1/20\n95/95 [==============================] - 2s 17ms/step - loss: 0.6141 - tp: 176.0000 - fp: 46022.0000 - tn: 147898.0000 - fn: 158.0000 - accuracy: 0.7623 - precision: 0.0038 - recall: 0.5269 - auc: 0.6217 - val_loss: 0.3774 - val_tp: 10.0000 - val_fp: 5.0000 - val_tn: 10200.0000 - val_fn: 9.0000 - val_accuracy: 0.9986 - val_precision: 0.6667 - val_recall: 0.5263 - val_auc: 0.7773\nEpoch 2/20\n95/95 [==============================] - 1s 10ms/step - loss: 0.3044 - tp: 120.0000 - fp: 5156.0000 - tn: 188764.0000 - fn: 214.0000 - accuracy: 0.9724 - precision: 0.0227 - recall: 0.3593 - auc: 0.5793 - val_loss: 0.1517 - val_tp: 10.0000 - val_fp: 1.0000 - val_tn: 10204.0000 - val_fn: 9.0000 - val_accuracy: 0.9990 - val_precision: 0.9091 - val_recall: 0.5263 - val_auc: 0.7088\nEpoch 3/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.1281 - tp: 117.0000 - fp: 1328.0000 - tn: 192592.0000 - fn: 217.0000 - accuracy: 0.9920 - precision: 0.0810 - recall: 0.3503 - auc: 0.5967 - val_loss: 0.0651 - val_tp: 10.0000 - val_fp: 1.0000 - val_tn: 10204.0000 - val_fn: 9.0000 - val_accuracy: 0.9990 - val_precision: 0.9091 - val_recall: 0.5263 - val_auc: 0.7391\nEpoch 4/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.0632 - tp: 104.0000 - fp: 531.0000 - tn: 193389.0000 - fn: 230.0000 - accuracy: 0.9961 - precision: 0.1638 - recall: 0.3114 - auc: 0.6196 - val_loss: 0.0336 - val_tp: 10.0000 - val_fp: 2.0000 - val_tn: 10203.0000 - val_fn: 9.0000 - val_accuracy: 0.9989 - val_precision: 0.8333 - val_recall: 0.5263 - val_auc: 0.7590\nEpoch 5/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.0393 - tp: 117.0000 - fp: 305.0000 - tn: 193615.0000 - fn: 217.0000 - accuracy: 0.9973 - precision: 0.2773 - recall: 0.3503 - auc: 0.6451 - val_loss: 0.0214 - val_tp: 10.0000 - val_fp: 1.0000 - val_tn: 10204.0000 - val_fn: 9.0000 - val_accuracy: 0.9990 - val_precision: 0.9091 - val_recall: 0.5263 - val_auc: 0.7735\nEpoch 6/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.0266 - tp: 122.0000 - fp: 196.0000 - tn: 193724.0000 - fn: 212.0000 - accuracy: 0.9979 - precision: 0.3836 - recall: 0.3653 - auc: 0.7099 - val_loss: 0.0153 - val_tp: 10.0000 - val_fp: 2.0000 - val_tn: 10203.0000 - val_fn: 9.0000 - val_accuracy: 0.9989 - val_precision: 0.8333 - val_recall: 0.5263 - val_auc: 0.8267\nEpoch 7/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.0219 - tp: 136.0000 - fp: 152.0000 - tn: 193768.0000 - fn: 198.0000 - accuracy: 0.9982 - precision: 0.4722 - recall: 0.4072 - auc: 0.7056 - val_loss: 0.0115 - val_tp: 11.0000 - val_fp: 2.0000 - val_tn: 10203.0000 - val_fn: 8.0000 - val_accuracy: 0.9990 - val_precision: 0.8462 - val_recall: 0.5789 - val_auc: 0.8699\nEpoch 8/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.0175 - tp: 134.0000 - fp: 127.0000 - tn: 193793.0000 - fn: 200.0000 - accuracy: 0.9983 - precision: 0.5134 - recall: 0.4012 - auc: 0.7606 - val_loss: 0.0098 - val_tp: 10.0000 - val_fp: 1.0000 - val_tn: 10204.0000 - val_fn: 9.0000 - val_accuracy: 0.9990 - val_precision: 0.9091 - val_recall: 0.5263 - val_auc: 0.8520\nEpoch 9/20\n95/95 [==============================] - 1s 13ms/step - loss: 0.0154 - tp: 142.0000 - fp: 102.0000 - tn: 193818.0000 - fn: 192.0000 - accuracy: 0.9985 - precision: 0.5820 - recall: 0.4251 - auc: 0.7700 - val_loss: 0.0085 - val_tp: 10.0000 - val_fp: 1.0000 - val_tn: 10204.0000 - val_fn: 9.0000 - val_accuracy: 0.9990 - val_precision: 0.9091 - val_recall: 0.5263 - val_auc: 0.8808\nEpoch 10/20\n95/95 [==============================] - 1s 9ms/step - loss: 0.0126 - tp: 142.0000 - fp: 83.0000 - tn: 193837.0000 - fn: 192.0000 - accuracy: 0.9986 - precision: 0.6311 - recall: 0.4251 - auc: 0.8446 - val_loss: 0.0074 - val_tp: 11.0000 - val_fp: 2.0000 - val_tn: 10203.0000 - val_fn: 8.0000 - val_accuracy: 0.9990 - val_precision: 0.8462 - val_recall: 0.5789 - val_auc: 0.8895\nEpoch 11/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.0113 - tp: 153.0000 - fp: 92.0000 - tn: 193828.0000 - fn: 181.0000 - accuracy: 0.9986 - precision: 0.6245 - recall: 0.4581 - auc: 0.8725 - val_loss: 0.0069 - val_tp: 11.0000 - val_fp: 2.0000 - val_tn: 10203.0000 - val_fn: 8.0000 - val_accuracy: 0.9990 - val_precision: 0.8462 - val_recall: 0.5789 - val_auc: 0.8670\nEpoch 12/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.0101 - tp: 165.0000 - fp: 67.0000 - tn: 193853.0000 - fn: 169.0000 - accuracy: 0.9988 - precision: 0.7112 - recall: 0.4940 - auc: 0.8850 - val_loss: 0.0064 - val_tp: 11.0000 - val_fp: 2.0000 - val_tn: 10203.0000 - val_fn: 8.0000 - val_accuracy: 0.9990 - val_precision: 0.8462 - val_recall: 0.5789 - val_auc: 0.8680\nEpoch 13/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.0101 - tp: 151.0000 - fp: 69.0000 - tn: 193851.0000 - fn: 183.0000 - accuracy: 0.9987 - precision: 0.6864 - recall: 0.4521 - auc: 0.8702 - val_loss: 0.0061 - val_tp: 11.0000 - val_fp: 2.0000 - val_tn: 10203.0000 - val_fn: 8.0000 - val_accuracy: 0.9990 - val_precision: 0.8462 - val_recall: 0.5789 - val_auc: 0.8682\nEpoch 14/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.0086 - tp: 172.0000 - fp: 61.0000 - tn: 193859.0000 - fn: 162.0000 - accuracy: 0.9989 - precision: 0.7382 - recall: 0.5150 - auc: 0.8897 - val_loss: 0.0059 - val_tp: 11.0000 - val_fp: 2.0000 - val_tn: 10203.0000 - val_fn: 8.0000 - val_accuracy: 0.9990 - val_precision: 0.8462 - val_recall: 0.5789 - val_auc: 0.8930\nEpoch 15/20\n95/95 [==============================] - 1s 14ms/step - loss: 0.0083 - tp: 163.0000 - fp: 51.0000 - tn: 193869.0000 - fn: 171.0000 - accuracy: 0.9989 - precision: 0.7617 - recall: 0.4880 - auc: 0.8846 - val_loss: 0.0057 - val_tp: 11.0000 - val_fp: 2.0000 - val_tn: 10203.0000 - val_fn: 8.0000 - val_accuracy: 0.9990 - val_precision: 0.8462 - val_recall: 0.5789 - val_auc: 0.8683\nEpoch 16/20\n95/95 [==============================] - 1s 9ms/step - loss: 0.0082 - tp: 172.0000 - fp: 54.0000 - tn: 193866.0000 - fn: 162.0000 - accuracy: 0.9989 - precision: 0.7611 - recall: 0.5150 - auc: 0.8899 - val_loss: 0.0054 - val_tp: 11.0000 - val_fp: 2.0000 - val_tn: 10203.0000 - val_fn: 8.0000 - val_accuracy: 0.9990 - val_precision: 0.8462 - val_recall: 0.5789 - val_auc: 0.8945\nEpoch 17/20\n95/95 [==============================] - 1s 9ms/step - loss: 0.0079 - tp: 144.0000 - fp: 61.0000 - tn: 193859.0000 - fn: 190.0000 - accuracy: 0.9987 - precision: 0.7024 - recall: 0.4311 - auc: 0.9117 - val_loss: 0.0053 - val_tp: 12.0000 - val_fp: 2.0000 - val_tn: 10203.0000 - val_fn: 7.0000 - val_accuracy: 0.9991 - val_precision: 0.8571 - val_recall: 0.6316 - val_auc: 0.8682\nEpoch 18/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.0077 - tp: 171.0000 - fp: 62.0000 - tn: 193858.0000 - fn: 163.0000 - accuracy: 0.9988 - precision: 0.7339 - recall: 0.5120 - auc: 0.9105 - val_loss: 0.0053 - val_tp: 11.0000 - val_fp: 2.0000 - val_tn: 10203.0000 - val_fn: 8.0000 - val_accuracy: 0.9990 - val_precision: 0.8462 - val_recall: 0.5789 - val_auc: 0.8682\nEpoch 19/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.0068 - tp: 175.0000 - fp: 50.0000 - tn: 193870.0000 - fn: 159.0000 - accuracy: 0.9989 - precision: 0.7778 - recall: 0.5240 - auc: 0.9035 - val_loss: 0.0051 - val_tp: 12.0000 - val_fp: 2.0000 - val_tn: 10203.0000 - val_fn: 7.0000 - val_accuracy: 0.9991 - val_precision: 0.8571 - val_recall: 0.6316 - val_auc: 0.8946\nEpoch 20/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.0066 - tp: 169.0000 - fp: 46.0000 - tn: 193874.0000 - fn: 165.0000 - accuracy: 0.9989 - precision: 0.7860 - recall: 0.5060 - auc: 0.9044 - val_loss: 0.0051 - val_tp: 12.0000 - val_fp: 2.0000 - val_tn: 10203.0000 - val_fn: 7.0000 - val_accuracy: 0.9991 - val_precision: 0.8571 - val_recall: 0.6316 - val_auc: 0.8941\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model summary\nmodel.summary()","execution_count":14,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 29)                870       \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 29)                116       \n_________________________________________________________________\ndropout (Dropout)            (None, 29)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 29)                870       \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 29)                116       \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 29)                0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 29)                870       \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 29)                116       \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 29)                0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 30        \n=================================================================\nTotal params: 2,988\nTrainable params: 2,814\nNon-trainable params: 174\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate model performance on unseen data\nmodel.evaluate(X_test, y_test, batch_size=batch_size)","execution_count":15,"outputs":[{"output_type":"stream","text":"12/12 [==============================] - 0s 10ms/step - loss: 0.0054 - tp: 23.0000 - fp: 2.0000 - tn: 22679.0000 - fn: 16.0000 - accuracy: 0.9992 - precision: 0.9200 - recall: 0.5897 - auc: 0.9226\n","name":"stdout"},{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"[0.00541849248111248,\n 23.0,\n 2.0,\n 22679.0,\n 16.0,\n 0.9992077350616455,\n 0.9200000166893005,\n 0.5897436141967773,\n 0.9225940704345703]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"After trying a lot of combinations of different hyperparameters, the model performance is not that great in terms of different metrics. Let's explore weighted model next."},{"metadata":{},"cell_type":"markdown","source":"# Weighted Model"},{"metadata":{},"cell_type":"markdown","source":"We have more examples of negative class compared to the positive class. Letâ€™s force our model to pay attention to the underrepresented class. We can do that by passing weights for each class."},{"metadata":{"trusted":true},"cell_type":"code","source":"# get count of positive and negative class\nnegative_class, positive_class = np.bincount(df.Target_flag)\nprint(\"Count of Negative Instance, Positive Instance :\", negative_class, positive_class)\n\n# get number of total examples\ntotal_count = len(df.Target_flag)\nprint(\"Total Examples :\", total_count)\n\n# set weight for majority class\nweight_negative = (1 / negative_class) * (total_count) / 2.0\nprint(\"Weight for Majority Class :\", weight_negative)\n\n# set weight for minority class\nweight_positive = (1 / positive_class) * (total_count) / 2.0\nprint(\"Weight for Minority Class :\", weight_positive)\n\nclass_weights = {0: weight_negative, 1: weight_positive}","execution_count":16,"outputs":[{"output_type":"stream","text":"Count of Negative Instance, Positive Instance : 226806 392\nTotal Examples : 227198\nWeight for Majority Class : 0.5008641746691005\nWeight for Minority Class : 289.79336734693874\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training the model\nmodel = build_model(X_train, metrics=metrics)\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    batch_size=batch_size,\n    epochs=20,\n    validation_split=0.05,\n    shuffle=True,\n    verbose=1,\n    class_weight=class_weights\n)","execution_count":17,"outputs":[{"output_type":"stream","text":"Epoch 1/20\n95/95 [==============================] - 2s 18ms/step - loss: 0.6112 - tp: 284.0000 - fp: 49241.0000 - tn: 167360.0000 - fn: 89.0000 - accuracy: 0.7726 - precision: 0.0057 - recall: 0.7614 - auc: 0.8296 - val_loss: 0.4162 - val_tp: 12.0000 - val_fp: 474.0000 - val_tn: 9731.0000 - val_fn: 7.0000 - val_accuracy: 0.9530 - val_precision: 0.0247 - val_recall: 0.6316 - val_auc: 0.8495\nEpoch 2/20\n95/95 [==============================] - 1s 9ms/step - loss: 0.4466 - tp: 269.0000 - fp: 26374.0000 - tn: 167546.0000 - fn: 65.0000 - accuracy: 0.8639 - precision: 0.0101 - recall: 0.8054 - auc: 0.8934 - val_loss: 0.2599 - val_tp: 13.0000 - val_fp: 276.0000 - val_tn: 9929.0000 - val_fn: 6.0000 - val_accuracy: 0.9724 - val_precision: 0.0450 - val_recall: 0.6842 - val_auc: 0.8764\nEpoch 3/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.3630 - tp: 280.0000 - fp: 18493.0000 - tn: 175427.0000 - fn: 54.0000 - accuracy: 0.9045 - precision: 0.0149 - recall: 0.8383 - auc: 0.9260 - val_loss: 0.2014 - val_tp: 12.0000 - val_fp: 198.0000 - val_tn: 10007.0000 - val_fn: 7.0000 - val_accuracy: 0.9799 - val_precision: 0.0571 - val_recall: 0.6316 - val_auc: 0.8780\nEpoch 4/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.3230 - tp: 287.0000 - fp: 16298.0000 - tn: 177622.0000 - fn: 47.0000 - accuracy: 0.9159 - precision: 0.0173 - recall: 0.8593 - auc: 0.9410 - val_loss: 0.1395 - val_tp: 13.0000 - val_fp: 100.0000 - val_tn: 10105.0000 - val_fn: 6.0000 - val_accuracy: 0.9896 - val_precision: 0.1150 - val_recall: 0.6842 - val_auc: 0.8893\nEpoch 5/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.3013 - tp: 286.0000 - fp: 13540.0000 - tn: 180380.0000 - fn: 48.0000 - accuracy: 0.9301 - precision: 0.0207 - recall: 0.8563 - auc: 0.9491 - val_loss: 0.2024 - val_tp: 15.0000 - val_fp: 331.0000 - val_tn: 9874.0000 - val_fn: 4.0000 - val_accuracy: 0.9672 - val_precision: 0.0434 - val_recall: 0.7895 - val_auc: 0.8904\nEpoch 6/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.2732 - tp: 292.0000 - fp: 11494.0000 - tn: 182426.0000 - fn: 42.0000 - accuracy: 0.9406 - precision: 0.0248 - recall: 0.8743 - auc: 0.9518 - val_loss: 0.1255 - val_tp: 14.0000 - val_fp: 190.0000 - val_tn: 10015.0000 - val_fn: 5.0000 - val_accuracy: 0.9809 - val_precision: 0.0686 - val_recall: 0.7368 - val_auc: 0.9045\nEpoch 7/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.2669 - tp: 296.0000 - fp: 9984.0000 - tn: 183936.0000 - fn: 38.0000 - accuracy: 0.9484 - precision: 0.0288 - recall: 0.8862 - auc: 0.9549 - val_loss: 0.0961 - val_tp: 14.0000 - val_fp: 120.0000 - val_tn: 10085.0000 - val_fn: 5.0000 - val_accuracy: 0.9878 - val_precision: 0.1045 - val_recall: 0.7368 - val_auc: 0.8942\nEpoch 8/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.2100 - tp: 302.0000 - fp: 9220.0000 - tn: 184700.0000 - fn: 32.0000 - accuracy: 0.9524 - precision: 0.0317 - recall: 0.9042 - auc: 0.9701 - val_loss: 0.0805 - val_tp: 14.0000 - val_fp: 77.0000 - val_tn: 10128.0000 - val_fn: 5.0000 - val_accuracy: 0.9920 - val_precision: 0.1538 - val_recall: 0.7368 - val_auc: 0.9046\nEpoch 9/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.2092 - tp: 305.0000 - fp: 7975.0000 - tn: 185945.0000 - fn: 29.0000 - accuracy: 0.9588 - precision: 0.0368 - recall: 0.9132 - auc: 0.9691 - val_loss: 0.0932 - val_tp: 14.0000 - val_fp: 98.0000 - val_tn: 10107.0000 - val_fn: 5.0000 - val_accuracy: 0.9899 - val_precision: 0.1250 - val_recall: 0.7368 - val_auc: 0.9382\nEpoch 10/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.2032 - tp: 302.0000 - fp: 7281.0000 - tn: 186639.0000 - fn: 32.0000 - accuracy: 0.9624 - precision: 0.0398 - recall: 0.9042 - auc: 0.9713 - val_loss: 0.1203 - val_tp: 14.0000 - val_fp: 205.0000 - val_tn: 10000.0000 - val_fn: 5.0000 - val_accuracy: 0.9795 - val_precision: 0.0639 - val_recall: 0.7368 - val_auc: 0.9211\nEpoch 11/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.2237 - tp: 300.0000 - fp: 8093.0000 - tn: 185827.0000 - fn: 34.0000 - accuracy: 0.9582 - precision: 0.0357 - recall: 0.8982 - auc: 0.9647 - val_loss: 0.1984 - val_tp: 15.0000 - val_fp: 400.0000 - val_tn: 9805.0000 - val_fn: 4.0000 - val_accuracy: 0.9605 - val_precision: 0.0361 - val_recall: 0.7895 - val_auc: 0.9531\nEpoch 12/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.2025 - tp: 307.0000 - fp: 7757.0000 - tn: 186163.0000 - fn: 27.0000 - accuracy: 0.9599 - precision: 0.0381 - recall: 0.9192 - auc: 0.9757 - val_loss: 0.0768 - val_tp: 14.0000 - val_fp: 85.0000 - val_tn: 10120.0000 - val_fn: 5.0000 - val_accuracy: 0.9912 - val_precision: 0.1414 - val_recall: 0.7368 - val_auc: 0.9759\nEpoch 13/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.1878 - tp: 303.0000 - fp: 6525.0000 - tn: 187395.0000 - fn: 31.0000 - accuracy: 0.9663 - precision: 0.0444 - recall: 0.9072 - auc: 0.9741 - val_loss: 0.1371 - val_tp: 14.0000 - val_fp: 248.0000 - val_tn: 9957.0000 - val_fn: 5.0000 - val_accuracy: 0.9753 - val_precision: 0.0534 - val_recall: 0.7368 - val_auc: 0.9721\nEpoch 14/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.1979 - tp: 296.0000 - fp: 6923.0000 - tn: 186997.0000 - fn: 38.0000 - accuracy: 0.9642 - precision: 0.0410 - recall: 0.8862 - auc: 0.9747 - val_loss: 0.1172 - val_tp: 14.0000 - val_fp: 196.0000 - val_tn: 10009.0000 - val_fn: 5.0000 - val_accuracy: 0.9803 - val_precision: 0.0667 - val_recall: 0.7368 - val_auc: 0.9749\nEpoch 15/20\n95/95 [==============================] - 1s 10ms/step - loss: 0.1821 - tp: 306.0000 - fp: 7786.0000 - tn: 186134.0000 - fn: 28.0000 - accuracy: 0.9598 - precision: 0.0378 - recall: 0.9162 - auc: 0.9796 - val_loss: 0.0796 - val_tp: 14.0000 - val_fp: 78.0000 - val_tn: 10127.0000 - val_fn: 5.0000 - val_accuracy: 0.9919 - val_precision: 0.1522 - val_recall: 0.7368 - val_auc: 0.9810\nEpoch 16/20\n95/95 [==============================] - 1s 9ms/step - loss: 0.1881 - tp: 304.0000 - fp: 7028.0000 - tn: 186892.0000 - fn: 30.0000 - accuracy: 0.9637 - precision: 0.0415 - recall: 0.9102 - auc: 0.9773 - val_loss: 0.3094 - val_tp: 15.0000 - val_fp: 679.0000 - val_tn: 9526.0000 - val_fn: 4.0000 - val_accuracy: 0.9332 - val_precision: 0.0216 - val_recall: 0.7895 - val_auc: 0.9476\nEpoch 17/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.2003 - tp: 303.0000 - fp: 6547.0000 - tn: 187373.0000 - fn: 31.0000 - accuracy: 0.9661 - precision: 0.0442 - recall: 0.9072 - auc: 0.9739 - val_loss: 0.1164 - val_tp: 15.0000 - val_fp: 191.0000 - val_tn: 10014.0000 - val_fn: 4.0000 - val_accuracy: 0.9809 - val_precision: 0.0728 - val_recall: 0.7895 - val_auc: 0.9677\nEpoch 18/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.1833 - tp: 307.0000 - fp: 6341.0000 - tn: 187579.0000 - fn: 27.0000 - accuracy: 0.9672 - precision: 0.0462 - recall: 0.9192 - auc: 0.9763 - val_loss: 0.0639 - val_tp: 14.0000 - val_fp: 70.0000 - val_tn: 10135.0000 - val_fn: 5.0000 - val_accuracy: 0.9927 - val_precision: 0.1667 - val_recall: 0.7368 - val_auc: 0.9845\nEpoch 19/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.1657 - tp: 306.0000 - fp: 6651.0000 - tn: 187269.0000 - fn: 28.0000 - accuracy: 0.9656 - precision: 0.0440 - recall: 0.9162 - auc: 0.9808 - val_loss: 0.0671 - val_tp: 14.0000 - val_fp: 76.0000 - val_tn: 10129.0000 - val_fn: 5.0000 - val_accuracy: 0.9921 - val_precision: 0.1556 - val_recall: 0.7368 - val_auc: 0.9903\nEpoch 20/20\n95/95 [==============================] - 1s 8ms/step - loss: 0.1664 - tp: 308.0000 - fp: 6014.0000 - tn: 187906.0000 - fn: 26.0000 - accuracy: 0.9689 - precision: 0.0487 - recall: 0.9222 - auc: 0.9778 - val_loss: 0.0669 - val_tp: 14.0000 - val_fp: 90.0000 - val_tn: 10115.0000 - val_fn: 5.0000 - val_accuracy: 0.9907 - val_precision: 0.1346 - val_recall: 0.7368 - val_auc: 0.9905\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate model performance on unseen data\nmodel.evaluate(X_test, y_test, batch_size=batch_size)","execution_count":18,"outputs":[{"output_type":"stream","text":"12/12 [==============================] - 0s 5ms/step - loss: 0.0610 - tp: 33.0000 - fp: 155.0000 - tn: 22526.0000 - fn: 6.0000 - accuracy: 0.9929 - precision: 0.1755 - recall: 0.8462 - auc: 0.9878\n","name":"stdout"},{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"[0.06097414717078209,\n 33.0,\n 155.0,\n 22526.0,\n 6.0,\n 0.9929137229919434,\n 0.17553190886974335,\n 0.8461538553237915,\n 0.9877967834472656]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"After trying a lot of combinations of different hyperparameters,although there has been considerable improvement in other metrics, the precision of the model is found to be extremely low."},{"metadata":{},"cell_type":"markdown","source":"# Oversample Minority Class"},{"metadata":{},"cell_type":"markdown","source":"Over-Sampling increases the number of instances in the minority class by randomly replicating them in order to present a higher representation of the minority class in the sample."},{"metadata":{"trusted":true},"cell_type":"code","source":"# seperate the features and target variables\nlabels = df.columns[1:30]\nX = df[labels]\ny = df['Target_flag']\n\n# create train-test split with stratify  \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=7, stratify=y)\nX = pd.concat([X_train, y_train], axis=1)\n\n# seperate the majority and minority classes\nnegative_class = X[X.Target_flag == 0]\npositive_class = X[X.Target_flag == 1]","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# length of minority class\nprint(\"Length of Minority Class :\", len(positive_class))","execution_count":20,"outputs":[{"output_type":"stream","text":"Length of Minority Class : 353\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# upsampling minority class\npositive_upsampled = resample(positive_class,\n                          replace=True,\n                          n_samples=len(negative_class),\n                          random_state=7)","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# length of upsampled  minority class\nprint(\"Length of Upsampled Minority Class :\", len(positive_upsampled))","execution_count":22,"outputs":[{"output_type":"stream","text":"Length of Upsampled Minority Class : 204125\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# combine negative class and upsampled positive class\noversampled_data = pd.concat([negative_class, positive_upsampled], axis=0)","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check new data\noversampled_data","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"        Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n22186   -0.923124  -0.341242  -1.207207  -4.585854   1.033464  -0.348103   \n221886  -2.012659  -0.195138   2.002589  -0.536759  -0.299436  -0.102073   \n56887    0.676771  -1.350408   0.694895   0.221955  -1.175833   0.639744   \n62117   -0.639618   0.560891   1.487671  -1.534404  -0.569355   0.239651   \n9214    -1.407331   1.607340   0.464506  -0.334922   0.087982  -0.851665   \n...           ...        ...        ...        ...        ...        ...   \n164077   0.364377   1.443523  -2.220907   2.036985  -1.237055  -1.728161   \n200118  -1.548788   1.808698  -0.953509   2.213085  -2.015728  -0.913457   \n125611  -2.740483   3.658095  -4.110636   5.340242  -2.666775  -0.092782   \n72212   -3.975939  -1.244939  -3.707414   4.544772   4.050676  -3.407679   \n79634  -11.682215   6.332882 -13.297109   7.690772 -10.889891  -2.792360   \n\n        Feature_7  Feature_8  Feature_9  Feature_10  ...  Feature_21  \\\n22186    0.375391   0.476410   0.010088   -1.615664  ...    0.020497   \n221886  -1.214421  -2.373126   0.437249   -1.480027  ...   -1.480635   \n56887   -0.620011   0.383131   1.168366   -0.395008  ...   -0.046101   \n62117   -0.416560   0.714844   0.676186   -1.638879  ...    0.173382   \n9214     0.467961   0.574703  -0.767013   -1.337393  ...   -0.139035   \n...           ...        ...        ...         ...  ...         ...   \n164077  -2.058582   0.358895  -1.393306   -3.505790  ...    0.402730   \n200118  -2.356013   1.197169  -1.678374   -3.538650  ...    0.855138   \n125611  -4.388699  -0.280133  -2.821895   -4.466284  ...    2.417495   \n72212   -5.063118   1.007042  -3.190158   -4.250717  ...    1.059737   \n79634  -12.561783   7.287122  -7.570322  -12.835738  ...    2.133456   \n\n        Feature_22  Feature_23  Feature_24  Feature_25  Feature_26  \\\n22186     0.595268    0.014555   -0.349121   -0.284302   -0.950774   \n221886    0.423519    0.985501    0.661672    0.037246    0.817614   \n56887    -0.499162   -0.139720   -0.263602   -0.064527    0.954492   \n62117     0.632067   -0.177002   -0.258803    0.065025   -0.695940   \n9214     -0.583866   -0.338291   -0.097976    0.748038   -0.338749   \n...            ...         ...         ...         ...         ...   \n164077   -0.132129   -0.032977    0.460861    0.560404    0.409366   \n200118    0.774745    0.059037    0.343200   -0.468938   -0.278338   \n125611   -0.097712    0.382155   -0.154757   -0.403956    0.277895   \n72212    -0.037395    0.348707   -0.162929    0.410531   -0.123612   \n79634    -1.271509   -0.035304    0.615054    0.349024   -0.428923   \n\n        Feature_27  Feature_28  Feature_29  Target_flag  \n22186     0.396593    0.132040       31.20            0  \n221886    0.332701    0.000969       30.00            0  \n56887    -0.077430    0.036478      251.99            0  \n62117     0.014810   -0.036132        1.00            0  \n9214     -0.331576   -0.099529        1.00            0  \n...            ...         ...         ...          ...  \n164077    0.539668    0.296918        0.76            1  \n200118    0.625922    0.395573       76.94            1  \n125611    0.830062    0.218690      112.33            1  \n72212     0.877424    0.667568        8.30            1  \n79634    -0.694935   -0.818970      173.07            1  \n\n[408250 rows x 30 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature_1</th>\n      <th>Feature_2</th>\n      <th>Feature_3</th>\n      <th>Feature_4</th>\n      <th>Feature_5</th>\n      <th>Feature_6</th>\n      <th>Feature_7</th>\n      <th>Feature_8</th>\n      <th>Feature_9</th>\n      <th>Feature_10</th>\n      <th>...</th>\n      <th>Feature_21</th>\n      <th>Feature_22</th>\n      <th>Feature_23</th>\n      <th>Feature_24</th>\n      <th>Feature_25</th>\n      <th>Feature_26</th>\n      <th>Feature_27</th>\n      <th>Feature_28</th>\n      <th>Feature_29</th>\n      <th>Target_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>22186</th>\n      <td>-0.923124</td>\n      <td>-0.341242</td>\n      <td>-1.207207</td>\n      <td>-4.585854</td>\n      <td>1.033464</td>\n      <td>-0.348103</td>\n      <td>0.375391</td>\n      <td>0.476410</td>\n      <td>0.010088</td>\n      <td>-1.615664</td>\n      <td>...</td>\n      <td>0.020497</td>\n      <td>0.595268</td>\n      <td>0.014555</td>\n      <td>-0.349121</td>\n      <td>-0.284302</td>\n      <td>-0.950774</td>\n      <td>0.396593</td>\n      <td>0.132040</td>\n      <td>31.20</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>221886</th>\n      <td>-2.012659</td>\n      <td>-0.195138</td>\n      <td>2.002589</td>\n      <td>-0.536759</td>\n      <td>-0.299436</td>\n      <td>-0.102073</td>\n      <td>-1.214421</td>\n      <td>-2.373126</td>\n      <td>0.437249</td>\n      <td>-1.480027</td>\n      <td>...</td>\n      <td>-1.480635</td>\n      <td>0.423519</td>\n      <td>0.985501</td>\n      <td>0.661672</td>\n      <td>0.037246</td>\n      <td>0.817614</td>\n      <td>0.332701</td>\n      <td>0.000969</td>\n      <td>30.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>56887</th>\n      <td>0.676771</td>\n      <td>-1.350408</td>\n      <td>0.694895</td>\n      <td>0.221955</td>\n      <td>-1.175833</td>\n      <td>0.639744</td>\n      <td>-0.620011</td>\n      <td>0.383131</td>\n      <td>1.168366</td>\n      <td>-0.395008</td>\n      <td>...</td>\n      <td>-0.046101</td>\n      <td>-0.499162</td>\n      <td>-0.139720</td>\n      <td>-0.263602</td>\n      <td>-0.064527</td>\n      <td>0.954492</td>\n      <td>-0.077430</td>\n      <td>0.036478</td>\n      <td>251.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>62117</th>\n      <td>-0.639618</td>\n      <td>0.560891</td>\n      <td>1.487671</td>\n      <td>-1.534404</td>\n      <td>-0.569355</td>\n      <td>0.239651</td>\n      <td>-0.416560</td>\n      <td>0.714844</td>\n      <td>0.676186</td>\n      <td>-1.638879</td>\n      <td>...</td>\n      <td>0.173382</td>\n      <td>0.632067</td>\n      <td>-0.177002</td>\n      <td>-0.258803</td>\n      <td>0.065025</td>\n      <td>-0.695940</td>\n      <td>0.014810</td>\n      <td>-0.036132</td>\n      <td>1.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9214</th>\n      <td>-1.407331</td>\n      <td>1.607340</td>\n      <td>0.464506</td>\n      <td>-0.334922</td>\n      <td>0.087982</td>\n      <td>-0.851665</td>\n      <td>0.467961</td>\n      <td>0.574703</td>\n      <td>-0.767013</td>\n      <td>-1.337393</td>\n      <td>...</td>\n      <td>-0.139035</td>\n      <td>-0.583866</td>\n      <td>-0.338291</td>\n      <td>-0.097976</td>\n      <td>0.748038</td>\n      <td>-0.338749</td>\n      <td>-0.331576</td>\n      <td>-0.099529</td>\n      <td>1.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>164077</th>\n      <td>0.364377</td>\n      <td>1.443523</td>\n      <td>-2.220907</td>\n      <td>2.036985</td>\n      <td>-1.237055</td>\n      <td>-1.728161</td>\n      <td>-2.058582</td>\n      <td>0.358895</td>\n      <td>-1.393306</td>\n      <td>-3.505790</td>\n      <td>...</td>\n      <td>0.402730</td>\n      <td>-0.132129</td>\n      <td>-0.032977</td>\n      <td>0.460861</td>\n      <td>0.560404</td>\n      <td>0.409366</td>\n      <td>0.539668</td>\n      <td>0.296918</td>\n      <td>0.76</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>200118</th>\n      <td>-1.548788</td>\n      <td>1.808698</td>\n      <td>-0.953509</td>\n      <td>2.213085</td>\n      <td>-2.015728</td>\n      <td>-0.913457</td>\n      <td>-2.356013</td>\n      <td>1.197169</td>\n      <td>-1.678374</td>\n      <td>-3.538650</td>\n      <td>...</td>\n      <td>0.855138</td>\n      <td>0.774745</td>\n      <td>0.059037</td>\n      <td>0.343200</td>\n      <td>-0.468938</td>\n      <td>-0.278338</td>\n      <td>0.625922</td>\n      <td>0.395573</td>\n      <td>76.94</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>125611</th>\n      <td>-2.740483</td>\n      <td>3.658095</td>\n      <td>-4.110636</td>\n      <td>5.340242</td>\n      <td>-2.666775</td>\n      <td>-0.092782</td>\n      <td>-4.388699</td>\n      <td>-0.280133</td>\n      <td>-2.821895</td>\n      <td>-4.466284</td>\n      <td>...</td>\n      <td>2.417495</td>\n      <td>-0.097712</td>\n      <td>0.382155</td>\n      <td>-0.154757</td>\n      <td>-0.403956</td>\n      <td>0.277895</td>\n      <td>0.830062</td>\n      <td>0.218690</td>\n      <td>112.33</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>72212</th>\n      <td>-3.975939</td>\n      <td>-1.244939</td>\n      <td>-3.707414</td>\n      <td>4.544772</td>\n      <td>4.050676</td>\n      <td>-3.407679</td>\n      <td>-5.063118</td>\n      <td>1.007042</td>\n      <td>-3.190158</td>\n      <td>-4.250717</td>\n      <td>...</td>\n      <td>1.059737</td>\n      <td>-0.037395</td>\n      <td>0.348707</td>\n      <td>-0.162929</td>\n      <td>0.410531</td>\n      <td>-0.123612</td>\n      <td>0.877424</td>\n      <td>0.667568</td>\n      <td>8.30</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>79634</th>\n      <td>-11.682215</td>\n      <td>6.332882</td>\n      <td>-13.297109</td>\n      <td>7.690772</td>\n      <td>-10.889891</td>\n      <td>-2.792360</td>\n      <td>-12.561783</td>\n      <td>7.287122</td>\n      <td>-7.570322</td>\n      <td>-12.835738</td>\n      <td>...</td>\n      <td>2.133456</td>\n      <td>-1.271509</td>\n      <td>-0.035304</td>\n      <td>0.615054</td>\n      <td>0.349024</td>\n      <td>-0.428923</td>\n      <td>-0.694935</td>\n      <td>-0.818970</td>\n      <td>173.07</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>408250 rows Ã— 30 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# seperate the features and target variables\nlabels = oversampled_data.columns[:30]\nX = oversampled_data[labels]\ny = oversampled_data['Target_flag']\n\n# create train-test split with stratify\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=7, stratify=y)","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check shape of created train-test split\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":26,"outputs":[{"output_type":"stream","text":"(367425, 30)\n(40825, 30)\n(367425,)\n(40825,)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training the model\nmodel = build_model(X_train, metrics=metrics)\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    batch_size=batch_size,\n    epochs=20,\n    validation_split=0.05,\n    shuffle=True,\n    verbose=1\n)","execution_count":27,"outputs":[{"output_type":"stream","text":"Epoch 1/20\n171/171 [==============================] - 2s 15ms/step - loss: 0.2982 - tp: 148096.0000 - fp: 15704.0000 - tn: 181550.0000 - fn: 26423.0000 - accuracy: 0.8867 - precision: 0.9041 - recall: 0.8486 - auc: 0.9503 - val_loss: 0.1450 - val_tp: 8863.0000 - val_fp: 579.0000 - val_tn: 8561.0000 - val_fn: 369.0000 - val_accuracy: 0.9484 - val_precision: 0.9387 - val_recall: 0.9600 - val_auc: 0.9903\nEpoch 2/20\n171/171 [==============================] - 1s 8ms/step - loss: 0.0867 - tp: 168511.0000 - fp: 4601.0000 - tn: 169972.0000 - fn: 5969.0000 - accuracy: 0.9697 - precision: 0.9734 - recall: 0.9658 - auc: 0.9950 - val_loss: 0.0504 - val_tp: 9005.0000 - val_fp: 171.0000 - val_tn: 8969.0000 - val_fn: 227.0000 - val_accuracy: 0.9783 - val_precision: 0.9814 - val_recall: 0.9754 - val_auc: 0.9984\nEpoch 3/20\n171/171 [==============================] - 1s 8ms/step - loss: 0.0218 - tp: 173355.0000 - fp: 1176.0000 - tn: 173397.0000 - fn: 1125.0000 - accuracy: 0.9934 - precision: 0.9933 - recall: 0.9936 - auc: 0.9994 - val_loss: 0.0454 - val_tp: 9143.0000 - val_fp: 239.0000 - val_tn: 8901.0000 - val_fn: 89.0000 - val_accuracy: 0.9821 - val_precision: 0.9745 - val_recall: 0.9904 - val_auc: 0.9986\nEpoch 4/20\n171/171 [==============================] - 2s 10ms/step - loss: 0.0101 - tp: 174029.0000 - fp: 473.0000 - tn: 174100.0000 - fn: 451.0000 - accuracy: 0.9974 - precision: 0.9973 - recall: 0.9974 - auc: 0.9997 - val_loss: 0.0095 - val_tp: 9186.0000 - val_fp: 6.0000 - val_tn: 9134.0000 - val_fn: 46.0000 - val_accuracy: 0.9972 - val_precision: 0.9993 - val_recall: 0.9950 - val_auc: 0.9998\nEpoch 5/20\n171/171 [==============================] - 1s 8ms/step - loss: 0.0067 - tp: 174199.0000 - fp: 341.0000 - tn: 174232.0000 - fn: 281.0000 - accuracy: 0.9982 - precision: 0.9980 - recall: 0.9984 - auc: 0.9998 - val_loss: 0.0021 - val_tp: 9232.0000 - val_fp: 4.0000 - val_tn: 9136.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9998 - val_precision: 0.9996 - val_recall: 1.0000 - val_auc: 0.9998\nEpoch 6/20\n171/171 [==============================] - 1s 8ms/step - loss: 0.0068 - tp: 174184.0000 - fp: 339.0000 - tn: 174234.0000 - fn: 296.0000 - accuracy: 0.9982 - precision: 0.9981 - recall: 0.9983 - auc: 0.9998 - val_loss: 0.0017 - val_tp: 9232.0000 - val_fp: 4.0000 - val_tn: 9136.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9998 - val_precision: 0.9996 - val_recall: 1.0000 - val_auc: 0.9998\nEpoch 7/20\n171/171 [==============================] - 1s 8ms/step - loss: 0.0040 - tp: 174309.0000 - fp: 187.0000 - tn: 174386.0000 - fn: 171.0000 - accuracy: 0.9990 - precision: 0.9989 - recall: 0.9990 - auc: 0.9999 - val_loss: 0.0014 - val_tp: 9232.0000 - val_fp: 4.0000 - val_tn: 9136.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9998 - val_precision: 0.9996 - val_recall: 1.0000 - val_auc: 0.9998\nEpoch 8/20\n171/171 [==============================] - 1s 8ms/step - loss: 0.0043 - tp: 174273.0000 - fp: 208.0000 - tn: 174365.0000 - fn: 207.0000 - accuracy: 0.9988 - precision: 0.9988 - recall: 0.9988 - auc: 0.9999 - val_loss: 0.0025 - val_tp: 9210.0000 - val_fp: 4.0000 - val_tn: 9136.0000 - val_fn: 22.0000 - val_accuracy: 0.9986 - val_precision: 0.9996 - val_recall: 0.9976 - val_auc: 0.9998\nEpoch 9/20\n171/171 [==============================] - 2s 11ms/step - loss: 0.0035 - tp: 174313.0000 - fp: 162.0000 - tn: 174411.0000 - fn: 167.0000 - accuracy: 0.9991 - precision: 0.9991 - recall: 0.9990 - auc: 0.9999 - val_loss: 0.0013 - val_tp: 9232.0000 - val_fp: 4.0000 - val_tn: 9136.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9998 - val_precision: 0.9996 - val_recall: 1.0000 - val_auc: 0.9998\nEpoch 10/20\n171/171 [==============================] - 1s 8ms/step - loss: 0.0031 - tp: 174354.0000 - fp: 155.0000 - tn: 174418.0000 - fn: 126.0000 - accuracy: 0.9992 - precision: 0.9991 - recall: 0.9993 - auc: 0.9999 - val_loss: 9.6654e-04 - val_tp: 9232.0000 - val_fp: 3.0000 - val_tn: 9137.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9998 - val_precision: 0.9997 - val_recall: 1.0000 - val_auc: 0.9999\nEpoch 11/20\n171/171 [==============================] - 1s 8ms/step - loss: 0.0032 - tp: 174337.0000 - fp: 138.0000 - tn: 174435.0000 - fn: 143.0000 - accuracy: 0.9992 - precision: 0.9992 - recall: 0.9992 - auc: 0.9999 - val_loss: 0.0013 - val_tp: 9232.0000 - val_fp: 4.0000 - val_tn: 9136.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9998 - val_precision: 0.9996 - val_recall: 1.0000 - val_auc: 0.9999\nEpoch 12/20\n171/171 [==============================] - 2s 9ms/step - loss: 0.0017 - tp: 174413.0000 - fp: 84.0000 - tn: 174489.0000 - fn: 67.0000 - accuracy: 0.9996 - precision: 0.9995 - recall: 0.9996 - auc: 0.9999 - val_loss: 6.5789e-04 - val_tp: 9232.0000 - val_fp: 3.0000 - val_tn: 9137.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9998 - val_precision: 0.9997 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 13/20\n171/171 [==============================] - 1s 8ms/step - loss: 0.0021 - tp: 174383.0000 - fp: 91.0000 - tn: 174482.0000 - fn: 97.0000 - accuracy: 0.9995 - precision: 0.9995 - recall: 0.9994 - auc: 0.9999 - val_loss: 5.2510e-04 - val_tp: 9232.0000 - val_fp: 3.0000 - val_tn: 9137.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9998 - val_precision: 0.9997 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 14/20\n171/171 [==============================] - 1s 8ms/step - loss: 0.0027 - tp: 174352.0000 - fp: 122.0000 - tn: 174451.0000 - fn: 128.0000 - accuracy: 0.9993 - precision: 0.9993 - recall: 0.9993 - auc: 0.9999 - val_loss: 4.5562e-04 - val_tp: 9232.0000 - val_fp: 3.0000 - val_tn: 9137.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9998 - val_precision: 0.9997 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 15/20\n171/171 [==============================] - 1s 8ms/step - loss: 0.0018 - tp: 174400.0000 - fp: 84.0000 - tn: 174489.0000 - fn: 80.0000 - accuracy: 0.9995 - precision: 0.9995 - recall: 0.9995 - auc: 0.9999 - val_loss: 0.0017 - val_tp: 9210.0000 - val_fp: 3.0000 - val_tn: 9137.0000 - val_fn: 22.0000 - val_accuracy: 0.9986 - val_precision: 0.9997 - val_recall: 0.9976 - val_auc: 1.0000\nEpoch 16/20\n171/171 [==============================] - 1s 8ms/step - loss: 0.0014 - tp: 174420.0000 - fp: 65.0000 - tn: 174508.0000 - fn: 60.0000 - accuracy: 0.9996 - precision: 0.9996 - recall: 0.9997 - auc: 1.0000 - val_loss: 2.3821e-04 - val_tp: 9232.0000 - val_fp: 1.0000 - val_tn: 9139.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9999 - val_precision: 0.9999 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 17/20\n171/171 [==============================] - 1s 8ms/step - loss: 0.0034 - tp: 174306.0000 - fp: 175.0000 - tn: 174398.0000 - fn: 174.0000 - accuracy: 0.9990 - precision: 0.9990 - recall: 0.9990 - auc: 0.9999 - val_loss: 3.5251e-04 - val_tp: 9232.0000 - val_fp: 3.0000 - val_tn: 9137.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9998 - val_precision: 0.9997 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 18/20\n171/171 [==============================] - 1s 8ms/step - loss: 0.0015 - tp: 174408.0000 - fp: 72.0000 - tn: 174501.0000 - fn: 72.0000 - accuracy: 0.9996 - precision: 0.9996 - recall: 0.9996 - auc: 0.9999 - val_loss: 1.2327e-04 - val_tp: 9232.0000 - val_fp: 1.0000 - val_tn: 9139.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9999 - val_precision: 0.9999 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 19/20\n171/171 [==============================] - 1s 8ms/step - loss: 0.0011 - tp: 174427.0000 - fp: 59.0000 - tn: 174514.0000 - fn: 53.0000 - accuracy: 0.9997 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - val_loss: 5.7355e-04 - val_tp: 9232.0000 - val_fp: 3.0000 - val_tn: 9137.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9998 - val_precision: 0.9997 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 20/20\n171/171 [==============================] - 2s 10ms/step - loss: 0.0030 - tp: 174326.0000 - fp: 170.0000 - tn: 174403.0000 - fn: 154.0000 - accuracy: 0.9991 - precision: 0.9990 - recall: 0.9991 - auc: 0.9999 - val_loss: 5.9543e-05 - val_tp: 9232.0000 - val_fp: 0.0000e+00 - val_tn: 9140.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate model performance on unseen data\nmodel.evaluate(X_test, y_test, batch_size=batch_size)","execution_count":28,"outputs":[{"output_type":"stream","text":"20/20 [==============================] - 0s 5ms/step - loss: 1.8236e-05 - tp: 20413.0000 - fp: 0.0000e+00 - tn: 20412.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n","name":"stdout"},{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"[1.8236469259136356e-05, 20413.0, 0.0, 20412.0, 0.0, 1.0, 1.0, 1.0, 1.0]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"We can see considerable improvements now in our model performance. But oversampling increases the likelihood of overfitting since it replicates the minority class events."},{"metadata":{},"cell_type":"markdown","source":"# Undersample Majority Class"},{"metadata":{},"cell_type":"markdown","source":"Undersampling aims to balance class distribution by randomly eliminating majority class examples. This is done until the majority and minority class instances are balanced out.\nWeâ€™ll remove samples from the majority class and balance the data this way."},{"metadata":{"trusted":true},"cell_type":"code","source":"# seperate the features and target variables\nlabels = df.columns[1:30]\nX = df[labels]\ny = df['Target_flag']\n\n\n# create train-test split with stratify  \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=7, stratify=y)\nX = pd.concat([X_train, y_train], axis=1)\n\n# seperate the majority and minority classes\nnegative_class = X[X.Target_flag == 0]\npositive_class = X[X.Target_flag == 1]","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# length of majority class\nprint(\"Length of Majority Class :\", len(negative_class))","execution_count":30,"outputs":[{"output_type":"stream","text":"Length of Majority Class : 204125\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# downsampling majority class\nnegative_downsampled = resample(negative_class,\n                          replace=False,\n                          n_samples=len(positive_class),\n                          random_state=7)","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# length of downsampled majority class\nprint(\"Length of Downsampled Majority Class :\", len(negative_downsampled))","execution_count":32,"outputs":[{"output_type":"stream","text":"Length of Downsampled Majority Class : 353\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# combine negative dowsampled class and positive class\nundersampled_data = pd.concat([negative_downsampled, positive_class], axis=0)","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check new data\nundersampled_data","execution_count":34,"outputs":[{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"        Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n193797   1.906400  -0.573265  -1.009407   0.792257  -0.198142  -0.067769   \n143015   1.031841  -0.480074   1.284097   0.551383  -1.234127  -0.180908   \n44633    1.208691  -0.224328   0.318862  -0.317760  -0.630465  -0.565430   \n135008   2.017787  -0.933999  -0.125465  -1.514940  -1.165311  -0.303344   \n172548  -0.817895  -0.621163   2.106390  -1.394239  -0.621589   2.778371   \n...           ...        ...        ...        ...        ...        ...   \n52630   -0.419820  -1.155978  -2.092516   2.786750   0.736297  -0.167292   \n123402  -1.125092   3.682876  -6.556168   4.016731  -0.425571  -2.031210   \n181339  -0.443794   1.271395   1.206178   0.790371   0.418935  -0.848376   \n165973  -5.488032   3.329561  -5.996296   3.601720  -2.023926  -1.737393   \n94046   -5.140723   3.568751  -5.896245   4.164720  -4.091193  -1.989960   \n\n        Feature_7  Feature_8  Feature_9  Feature_10  ...  Feature_21  \\\n193797  -0.192298   0.030639   1.420956   -0.131447  ...   -0.365444   \n143015  -0.823551   0.095998   2.307650   -0.679066  ...   -0.001148   \n44633   -0.305962   0.096606   0.182844    0.001888  ...    0.077888   \n135008  -1.153623   0.077438   2.591155   -1.016055  ...    0.241294   \n172548   0.006265   0.554697  -0.574781    0.058164  ...    0.180020   \n...           ...        ...        ...         ...  ...         ...   \n52630    1.600027  -0.117427  -0.796954   -0.133950  ...    0.480640   \n123402  -2.650137   1.131249  -2.946890   -4.816401  ...    1.185580   \n181339   0.917691  -0.235511  -0.285692   -0.867900  ...    0.119279   \n165973  -4.396859   0.228394  -1.675884   -3.991785  ...    1.719631   \n94046   -5.472436   2.422821  -2.909735   -6.287803  ...    1.131130   \n\n        Feature_22  Feature_23  Feature_24  Feature_25  Feature_26  \\\n193797   -0.867700    0.272260    0.590118   -0.178745    0.074378   \n143015    0.236531    0.007198    0.420524    0.016228    1.075350   \n44633     0.180560    0.029645    0.283920    0.117552    1.455968   \n135008    0.968823    0.185530    0.723452   -0.284142   -0.210828   \n172548    0.918703    0.010010   -1.331956   -0.318719   -0.168814   \n...            ...         ...         ...         ...         ...   \n52630     0.533517    1.284645    0.516131   -0.602941   -0.305024   \n123402    1.348156   -0.053686    0.284122   -1.174469   -0.087832   \n181339    0.513479   -0.264243    0.443311    0.029516   -0.335141   \n165973    0.343209    0.133584    0.833340   -0.839776    0.502010   \n94046     0.118022   -0.332704    0.139941    0.324758   -0.180769   \n\n        Feature_27  Feature_28  Feature_29  Target_flag  \n193797   -0.050384   -0.045986       58.68            0  \n143015   -0.064337    0.018270       73.80            0  \n44633    -0.110750   -0.019538        4.99            0  \n135008    0.067739   -0.020727       14.72            0  \n172548   -0.031983   -0.182348      176.50            0  \n...            ...         ...         ...          ...  \n52630    -0.021363    0.129096      451.27            1  \n123402    0.718790    0.676216        0.76            1  \n181339   -0.188815   -0.123391        5.09            1  \n165973   -1.937473    1.521218        0.01            1  \n94046     0.177810    0.661555       99.90            1  \n\n[706 rows x 30 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature_1</th>\n      <th>Feature_2</th>\n      <th>Feature_3</th>\n      <th>Feature_4</th>\n      <th>Feature_5</th>\n      <th>Feature_6</th>\n      <th>Feature_7</th>\n      <th>Feature_8</th>\n      <th>Feature_9</th>\n      <th>Feature_10</th>\n      <th>...</th>\n      <th>Feature_21</th>\n      <th>Feature_22</th>\n      <th>Feature_23</th>\n      <th>Feature_24</th>\n      <th>Feature_25</th>\n      <th>Feature_26</th>\n      <th>Feature_27</th>\n      <th>Feature_28</th>\n      <th>Feature_29</th>\n      <th>Target_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>193797</th>\n      <td>1.906400</td>\n      <td>-0.573265</td>\n      <td>-1.009407</td>\n      <td>0.792257</td>\n      <td>-0.198142</td>\n      <td>-0.067769</td>\n      <td>-0.192298</td>\n      <td>0.030639</td>\n      <td>1.420956</td>\n      <td>-0.131447</td>\n      <td>...</td>\n      <td>-0.365444</td>\n      <td>-0.867700</td>\n      <td>0.272260</td>\n      <td>0.590118</td>\n      <td>-0.178745</td>\n      <td>0.074378</td>\n      <td>-0.050384</td>\n      <td>-0.045986</td>\n      <td>58.68</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>143015</th>\n      <td>1.031841</td>\n      <td>-0.480074</td>\n      <td>1.284097</td>\n      <td>0.551383</td>\n      <td>-1.234127</td>\n      <td>-0.180908</td>\n      <td>-0.823551</td>\n      <td>0.095998</td>\n      <td>2.307650</td>\n      <td>-0.679066</td>\n      <td>...</td>\n      <td>-0.001148</td>\n      <td>0.236531</td>\n      <td>0.007198</td>\n      <td>0.420524</td>\n      <td>0.016228</td>\n      <td>1.075350</td>\n      <td>-0.064337</td>\n      <td>0.018270</td>\n      <td>73.80</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>44633</th>\n      <td>1.208691</td>\n      <td>-0.224328</td>\n      <td>0.318862</td>\n      <td>-0.317760</td>\n      <td>-0.630465</td>\n      <td>-0.565430</td>\n      <td>-0.305962</td>\n      <td>0.096606</td>\n      <td>0.182844</td>\n      <td>0.001888</td>\n      <td>...</td>\n      <td>0.077888</td>\n      <td>0.180560</td>\n      <td>0.029645</td>\n      <td>0.283920</td>\n      <td>0.117552</td>\n      <td>1.455968</td>\n      <td>-0.110750</td>\n      <td>-0.019538</td>\n      <td>4.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>135008</th>\n      <td>2.017787</td>\n      <td>-0.933999</td>\n      <td>-0.125465</td>\n      <td>-1.514940</td>\n      <td>-1.165311</td>\n      <td>-0.303344</td>\n      <td>-1.153623</td>\n      <td>0.077438</td>\n      <td>2.591155</td>\n      <td>-1.016055</td>\n      <td>...</td>\n      <td>0.241294</td>\n      <td>0.968823</td>\n      <td>0.185530</td>\n      <td>0.723452</td>\n      <td>-0.284142</td>\n      <td>-0.210828</td>\n      <td>0.067739</td>\n      <td>-0.020727</td>\n      <td>14.72</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>172548</th>\n      <td>-0.817895</td>\n      <td>-0.621163</td>\n      <td>2.106390</td>\n      <td>-1.394239</td>\n      <td>-0.621589</td>\n      <td>2.778371</td>\n      <td>0.006265</td>\n      <td>0.554697</td>\n      <td>-0.574781</td>\n      <td>0.058164</td>\n      <td>...</td>\n      <td>0.180020</td>\n      <td>0.918703</td>\n      <td>0.010010</td>\n      <td>-1.331956</td>\n      <td>-0.318719</td>\n      <td>-0.168814</td>\n      <td>-0.031983</td>\n      <td>-0.182348</td>\n      <td>176.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>52630</th>\n      <td>-0.419820</td>\n      <td>-1.155978</td>\n      <td>-2.092516</td>\n      <td>2.786750</td>\n      <td>0.736297</td>\n      <td>-0.167292</td>\n      <td>1.600027</td>\n      <td>-0.117427</td>\n      <td>-0.796954</td>\n      <td>-0.133950</td>\n      <td>...</td>\n      <td>0.480640</td>\n      <td>0.533517</td>\n      <td>1.284645</td>\n      <td>0.516131</td>\n      <td>-0.602941</td>\n      <td>-0.305024</td>\n      <td>-0.021363</td>\n      <td>0.129096</td>\n      <td>451.27</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>123402</th>\n      <td>-1.125092</td>\n      <td>3.682876</td>\n      <td>-6.556168</td>\n      <td>4.016731</td>\n      <td>-0.425571</td>\n      <td>-2.031210</td>\n      <td>-2.650137</td>\n      <td>1.131249</td>\n      <td>-2.946890</td>\n      <td>-4.816401</td>\n      <td>...</td>\n      <td>1.185580</td>\n      <td>1.348156</td>\n      <td>-0.053686</td>\n      <td>0.284122</td>\n      <td>-1.174469</td>\n      <td>-0.087832</td>\n      <td>0.718790</td>\n      <td>0.676216</td>\n      <td>0.76</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>181339</th>\n      <td>-0.443794</td>\n      <td>1.271395</td>\n      <td>1.206178</td>\n      <td>0.790371</td>\n      <td>0.418935</td>\n      <td>-0.848376</td>\n      <td>0.917691</td>\n      <td>-0.235511</td>\n      <td>-0.285692</td>\n      <td>-0.867900</td>\n      <td>...</td>\n      <td>0.119279</td>\n      <td>0.513479</td>\n      <td>-0.264243</td>\n      <td>0.443311</td>\n      <td>0.029516</td>\n      <td>-0.335141</td>\n      <td>-0.188815</td>\n      <td>-0.123391</td>\n      <td>5.09</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>165973</th>\n      <td>-5.488032</td>\n      <td>3.329561</td>\n      <td>-5.996296</td>\n      <td>3.601720</td>\n      <td>-2.023926</td>\n      <td>-1.737393</td>\n      <td>-4.396859</td>\n      <td>0.228394</td>\n      <td>-1.675884</td>\n      <td>-3.991785</td>\n      <td>...</td>\n      <td>1.719631</td>\n      <td>0.343209</td>\n      <td>0.133584</td>\n      <td>0.833340</td>\n      <td>-0.839776</td>\n      <td>0.502010</td>\n      <td>-1.937473</td>\n      <td>1.521218</td>\n      <td>0.01</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>94046</th>\n      <td>-5.140723</td>\n      <td>3.568751</td>\n      <td>-5.896245</td>\n      <td>4.164720</td>\n      <td>-4.091193</td>\n      <td>-1.989960</td>\n      <td>-5.472436</td>\n      <td>2.422821</td>\n      <td>-2.909735</td>\n      <td>-6.287803</td>\n      <td>...</td>\n      <td>1.131130</td>\n      <td>0.118022</td>\n      <td>-0.332704</td>\n      <td>0.139941</td>\n      <td>0.324758</td>\n      <td>-0.180769</td>\n      <td>0.177810</td>\n      <td>0.661555</td>\n      <td>99.90</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>706 rows Ã— 30 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# seperate the features and target variables\nlabels = undersampled_data.columns[:30]\nX = undersampled_data[labels]\ny = undersampled_data['Target_flag']\n\n# create train-test split with stratify\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=7, stratify=y)","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check shape of created train-test split\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":36,"outputs":[{"output_type":"stream","text":"(635, 30)\n(71, 30)\n(635,)\n(71,)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training the model\nmodel = build_model(X_train, metrics=metrics)\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    batch_size=batch_size,\n    epochs=400,\n    validation_split=0.05,\n    shuffle=True,\n    verbose=1\n)","execution_count":37,"outputs":[{"output_type":"stream","text":"Epoch 1/400\n1/1 [==============================] - 1s 824ms/step - loss: 0.9075 - tp: 20548.0000 - fp: 159.0000 - tn: 20559.0000 - fn: 162.0000 - accuracy: 0.9923 - precision: 0.9923 - recall: 0.9922 - auc: 0.9998 - val_loss: 0.6319 - val_tp: 19.0000 - val_fp: 11.0000 - val_tn: 1.0000 - val_fn: 1.0000 - val_accuracy: 0.6250 - val_precision: 0.6333 - val_recall: 0.9500 - val_auc: 0.7000\nEpoch 2/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.9030 - tp: 125.0000 - fp: 165.0000 - tn: 141.0000 - fn: 172.0000 - accuracy: 0.4411 - precision: 0.4310 - recall: 0.4209 - auc: 0.4516 - val_loss: 0.6289 - val_tp: 19.0000 - val_fp: 11.0000 - val_tn: 1.0000 - val_fn: 1.0000 - val_accuracy: 0.6250 - val_precision: 0.6333 - val_recall: 0.9500 - val_auc: 0.7000\nEpoch 3/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.9352 - tp: 126.0000 - fp: 156.0000 - tn: 150.0000 - fn: 171.0000 - accuracy: 0.4577 - precision: 0.4468 - recall: 0.4242 - auc: 0.4369 - val_loss: 0.6211 - val_tp: 19.0000 - val_fp: 11.0000 - val_tn: 1.0000 - val_fn: 1.0000 - val_accuracy: 0.6250 - val_precision: 0.6333 - val_recall: 0.9500 - val_auc: 0.7042\nEpoch 4/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.8714 - tp: 126.0000 - fp: 151.0000 - tn: 155.0000 - fn: 171.0000 - accuracy: 0.4660 - precision: 0.4549 - recall: 0.4242 - auc: 0.4704 - val_loss: 0.6148 - val_tp: 19.0000 - val_fp: 11.0000 - val_tn: 1.0000 - val_fn: 1.0000 - val_accuracy: 0.6250 - val_precision: 0.6333 - val_recall: 0.9500 - val_auc: 0.7000\nEpoch 5/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.8484 - tp: 131.0000 - fp: 136.0000 - tn: 170.0000 - fn: 166.0000 - accuracy: 0.4992 - precision: 0.4906 - recall: 0.4411 - auc: 0.4987 - val_loss: 0.6069 - val_tp: 20.0000 - val_fp: 10.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6875 - val_precision: 0.6667 - val_recall: 1.0000 - val_auc: 0.7167\nEpoch 6/400\n1/1 [==============================] - 0s 161ms/step - loss: 0.8109 - tp: 137.0000 - fp: 130.0000 - tn: 176.0000 - fn: 160.0000 - accuracy: 0.5191 - precision: 0.5131 - recall: 0.4613 - auc: 0.5342 - val_loss: 0.6004 - val_tp: 20.0000 - val_fp: 10.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6875 - val_precision: 0.6667 - val_recall: 1.0000 - val_auc: 0.7208\nEpoch 7/400\n1/1 [==============================] - 0s 40ms/step - loss: 0.7813 - tp: 152.0000 - fp: 118.0000 - tn: 188.0000 - fn: 145.0000 - accuracy: 0.5638 - precision: 0.5630 - recall: 0.5118 - auc: 0.5787 - val_loss: 0.5935 - val_tp: 20.0000 - val_fp: 10.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6875 - val_precision: 0.6667 - val_recall: 1.0000 - val_auc: 0.7354\nEpoch 8/400\n1/1 [==============================] - 0s 38ms/step - loss: 0.7530 - tp: 154.0000 - fp: 115.0000 - tn: 191.0000 - fn: 143.0000 - accuracy: 0.5721 - precision: 0.5725 - recall: 0.5185 - auc: 0.6090 - val_loss: 0.5866 - val_tp: 20.0000 - val_fp: 10.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6875 - val_precision: 0.6667 - val_recall: 1.0000 - val_auc: 0.7562\nEpoch 9/400\n1/1 [==============================] - 0s 38ms/step - loss: 0.7600 - tp: 167.0000 - fp: 103.0000 - tn: 203.0000 - fn: 130.0000 - accuracy: 0.6136 - precision: 0.6185 - recall: 0.5623 - auc: 0.6551 - val_loss: 0.5807 - val_tp: 20.0000 - val_fp: 10.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6875 - val_precision: 0.6667 - val_recall: 1.0000 - val_auc: 0.7792\nEpoch 10/400\n1/1 [==============================] - 0s 42ms/step - loss: 0.6994 - tp: 170.0000 - fp: 89.0000 - tn: 217.0000 - fn: 127.0000 - accuracy: 0.6418 - precision: 0.6564 - recall: 0.5724 - auc: 0.6592 - val_loss: 0.5748 - val_tp: 20.0000 - val_fp: 10.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6875 - val_precision: 0.6667 - val_recall: 1.0000 - val_auc: 0.8000\nEpoch 11/400\n1/1 [==============================] - 0s 35ms/step - loss: 0.7033 - tp: 160.0000 - fp: 87.0000 - tn: 219.0000 - fn: 137.0000 - accuracy: 0.6285 - precision: 0.6478 - recall: 0.5387 - auc: 0.6800 - val_loss: 0.5691 - val_tp: 20.0000 - val_fp: 8.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7500 - val_precision: 0.7143 - val_recall: 1.0000 - val_auc: 0.8042\nEpoch 12/400\n1/1 [==============================] - 0s 38ms/step - loss: 0.6743 - tp: 170.0000 - fp: 77.0000 - tn: 229.0000 - fn: 127.0000 - accuracy: 0.6617 - precision: 0.6883 - recall: 0.5724 - auc: 0.7151 - val_loss: 0.5630 - val_tp: 20.0000 - val_fp: 8.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7500 - val_precision: 0.7143 - val_recall: 1.0000 - val_auc: 0.8125\nEpoch 13/400\n1/1 [==============================] - 0s 35ms/step - loss: 0.6412 - tp: 166.0000 - fp: 75.0000 - tn: 231.0000 - fn: 131.0000 - accuracy: 0.6584 - precision: 0.6888 - recall: 0.5589 - auc: 0.7011 - val_loss: 0.5572 - val_tp: 20.0000 - val_fp: 8.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7500 - val_precision: 0.7143 - val_recall: 1.0000 - val_auc: 0.8271\nEpoch 14/400\n1/1 [==============================] - 0s 36ms/step - loss: 0.6491 - tp: 180.0000 - fp: 75.0000 - tn: 231.0000 - fn: 117.0000 - accuracy: 0.6816 - precision: 0.7059 - recall: 0.6061 - auc: 0.7450 - val_loss: 0.5500 - val_tp: 20.0000 - val_fp: 7.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7812 - val_precision: 0.7407 - val_recall: 1.0000 - val_auc: 0.8437\nEpoch 15/400\n1/1 [==============================] - 0s 35ms/step - loss: 0.6086 - tp: 169.0000 - fp: 63.0000 - tn: 243.0000 - fn: 128.0000 - accuracy: 0.6833 - precision: 0.7284 - recall: 0.5690 - auc: 0.7358 - val_loss: 0.5426 - val_tp: 20.0000 - val_fp: 7.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7812 - val_precision: 0.7407 - val_recall: 1.0000 - val_auc: 0.8479\nEpoch 16/400\n1/1 [==============================] - 0s 32ms/step - loss: 0.5791 - tp: 191.0000 - fp: 66.0000 - tn: 240.0000 - fn: 106.0000 - accuracy: 0.7148 - precision: 0.7432 - recall: 0.6431 - auc: 0.7730 - val_loss: 0.5355 - val_tp: 20.0000 - val_fp: 7.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7812 - val_precision: 0.7407 - val_recall: 1.0000 - val_auc: 0.8729\nEpoch 17/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.5839 - tp: 183.0000 - fp: 59.0000 - tn: 247.0000 - fn: 114.0000 - accuracy: 0.7131 - precision: 0.7562 - recall: 0.6162 - auc: 0.7893 - val_loss: 0.5285 - val_tp: 20.0000 - val_fp: 7.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7812 - val_precision: 0.7407 - val_recall: 1.0000 - val_auc: 0.9021\nEpoch 18/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.5643 - tp: 200.0000 - fp: 54.0000 - tn: 252.0000 - fn: 97.0000 - accuracy: 0.7496 - precision: 0.7874 - recall: 0.6734 - auc: 0.7983 - val_loss: 0.5221 - val_tp: 20.0000 - val_fp: 6.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7692 - val_recall: 1.0000 - val_auc: 0.9229\nEpoch 19/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.5959 - tp: 185.0000 - fp: 60.0000 - tn: 246.0000 - fn: 112.0000 - accuracy: 0.7148 - precision: 0.7551 - recall: 0.6229 - auc: 0.7806 - val_loss: 0.5168 - val_tp: 20.0000 - val_fp: 6.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7692 - val_recall: 1.0000 - val_auc: 0.9333\nEpoch 20/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.5659 - tp: 202.0000 - fp: 50.0000 - tn: 256.0000 - fn: 95.0000 - accuracy: 0.7595 - precision: 0.8016 - recall: 0.6801 - auc: 0.8150 - val_loss: 0.5116 - val_tp: 20.0000 - val_fp: 6.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7692 - val_recall: 1.0000 - val_auc: 0.9396\nEpoch 21/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.5387 - tp: 207.0000 - fp: 59.0000 - tn: 247.0000 - fn: 90.0000 - accuracy: 0.7529 - precision: 0.7782 - recall: 0.6970 - auc: 0.8171 - val_loss: 0.5069 - val_tp: 20.0000 - val_fp: 6.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7692 - val_recall: 1.0000 - val_auc: 0.9500\nEpoch 22/400\n","name":"stdout"},{"output_type":"stream","text":"1/1 [==============================] - 0s 27ms/step - loss: 0.5590 - tp: 195.0000 - fp: 49.0000 - tn: 257.0000 - fn: 102.0000 - accuracy: 0.7496 - precision: 0.7992 - recall: 0.6566 - auc: 0.8216 - val_loss: 0.5021 - val_tp: 20.0000 - val_fp: 6.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7692 - val_recall: 1.0000 - val_auc: 0.9583\nEpoch 23/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.4969 - tp: 202.0000 - fp: 41.0000 - tn: 265.0000 - fn: 95.0000 - accuracy: 0.7745 - precision: 0.8313 - recall: 0.6801 - auc: 0.8517 - val_loss: 0.4972 - val_tp: 20.0000 - val_fp: 6.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7692 - val_recall: 1.0000 - val_auc: 0.9625\nEpoch 24/400\n1/1 [==============================] - 0s 41ms/step - loss: 0.4996 - tp: 216.0000 - fp: 57.0000 - tn: 249.0000 - fn: 81.0000 - accuracy: 0.7711 - precision: 0.7912 - recall: 0.7273 - auc: 0.8450 - val_loss: 0.4920 - val_tp: 20.0000 - val_fp: 6.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7692 - val_recall: 1.0000 - val_auc: 0.9625\nEpoch 25/400\n1/1 [==============================] - 0s 37ms/step - loss: 0.5105 - tp: 207.0000 - fp: 45.0000 - tn: 261.0000 - fn: 90.0000 - accuracy: 0.7761 - precision: 0.8214 - recall: 0.6970 - auc: 0.8432 - val_loss: 0.4864 - val_tp: 20.0000 - val_fp: 6.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7692 - val_recall: 1.0000 - val_auc: 0.9688\nEpoch 26/400\n1/1 [==============================] - 0s 37ms/step - loss: 0.5002 - tp: 218.0000 - fp: 54.0000 - tn: 252.0000 - fn: 79.0000 - accuracy: 0.7794 - precision: 0.8015 - recall: 0.7340 - auc: 0.8448 - val_loss: 0.4806 - val_tp: 20.0000 - val_fp: 6.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7692 - val_recall: 1.0000 - val_auc: 0.9688\nEpoch 27/400\n1/1 [==============================] - 0s 40ms/step - loss: 0.4812 - tp: 211.0000 - fp: 51.0000 - tn: 255.0000 - fn: 86.0000 - accuracy: 0.7728 - precision: 0.8053 - recall: 0.7104 - auc: 0.8557 - val_loss: 0.4746 - val_tp: 20.0000 - val_fp: 6.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7692 - val_recall: 1.0000 - val_auc: 0.9792\nEpoch 28/400\n1/1 [==============================] - 0s 44ms/step - loss: 0.4865 - tp: 218.0000 - fp: 50.0000 - tn: 256.0000 - fn: 79.0000 - accuracy: 0.7861 - precision: 0.8134 - recall: 0.7340 - auc: 0.8551 - val_loss: 0.4685 - val_tp: 20.0000 - val_fp: 6.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7692 - val_recall: 1.0000 - val_auc: 0.9854\nEpoch 29/400\n1/1 [==============================] - 0s 41ms/step - loss: 0.4864 - tp: 217.0000 - fp: 44.0000 - tn: 262.0000 - fn: 80.0000 - accuracy: 0.7944 - precision: 0.8314 - recall: 0.7306 - auc: 0.8550 - val_loss: 0.4625 - val_tp: 20.0000 - val_fp: 6.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7692 - val_recall: 1.0000 - val_auc: 0.9854\nEpoch 30/400\n1/1 [==============================] - 0s 36ms/step - loss: 0.4604 - tp: 223.0000 - fp: 46.0000 - tn: 260.0000 - fn: 74.0000 - accuracy: 0.8010 - precision: 0.8290 - recall: 0.7508 - auc: 0.8780 - val_loss: 0.4567 - val_tp: 20.0000 - val_fp: 6.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7692 - val_recall: 1.0000 - val_auc: 0.9854\nEpoch 31/400\n1/1 [==============================] - 0s 43ms/step - loss: 0.4499 - tp: 231.0000 - fp: 39.0000 - tn: 267.0000 - fn: 66.0000 - accuracy: 0.8259 - precision: 0.8556 - recall: 0.7778 - auc: 0.8769 - val_loss: 0.4510 - val_tp: 20.0000 - val_fp: 6.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7692 - val_recall: 1.0000 - val_auc: 0.9875\nEpoch 32/400\n1/1 [==============================] - 0s 40ms/step - loss: 0.4432 - tp: 225.0000 - fp: 36.0000 - tn: 270.0000 - fn: 72.0000 - accuracy: 0.8209 - precision: 0.8621 - recall: 0.7576 - auc: 0.8876 - val_loss: 0.4453 - val_tp: 20.0000 - val_fp: 6.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7692 - val_recall: 1.0000 - val_auc: 0.9875\nEpoch 33/400\n1/1 [==============================] - 0s 36ms/step - loss: 0.4469 - tp: 222.0000 - fp: 37.0000 - tn: 269.0000 - fn: 75.0000 - accuracy: 0.8143 - precision: 0.8571 - recall: 0.7475 - auc: 0.8906 - val_loss: 0.4399 - val_tp: 20.0000 - val_fp: 6.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7692 - val_recall: 1.0000 - val_auc: 0.9875\nEpoch 34/400\n1/1 [==============================] - 0s 35ms/step - loss: 0.4771 - tp: 229.0000 - fp: 49.0000 - tn: 257.0000 - fn: 68.0000 - accuracy: 0.8060 - precision: 0.8237 - recall: 0.7710 - auc: 0.8667 - val_loss: 0.4345 - val_tp: 20.0000 - val_fp: 6.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7692 - val_recall: 1.0000 - val_auc: 0.9875\nEpoch 35/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.4297 - tp: 239.0000 - fp: 31.0000 - tn: 275.0000 - fn: 58.0000 - accuracy: 0.8524 - precision: 0.8852 - recall: 0.8047 - auc: 0.8911 - val_loss: 0.4296 - val_tp: 20.0000 - val_fp: 6.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7692 - val_recall: 1.0000 - val_auc: 0.9875\nEpoch 36/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.4329 - tp: 228.0000 - fp: 39.0000 - tn: 267.0000 - fn: 69.0000 - accuracy: 0.8209 - precision: 0.8539 - recall: 0.7677 - auc: 0.8873 - val_loss: 0.4247 - val_tp: 20.0000 - val_fp: 6.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7692 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 37/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.4067 - tp: 235.0000 - fp: 26.0000 - tn: 280.0000 - fn: 62.0000 - accuracy: 0.8541 - precision: 0.9004 - recall: 0.7912 - auc: 0.9096 - val_loss: 0.4201 - val_tp: 20.0000 - val_fp: 6.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7692 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 38/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.4249 - tp: 232.0000 - fp: 39.0000 - tn: 267.0000 - fn: 65.0000 - accuracy: 0.8275 - precision: 0.8561 - recall: 0.7811 - auc: 0.8914 - val_loss: 0.4158 - val_tp: 20.0000 - val_fp: 5.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8438 - val_precision: 0.8000 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 39/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.3978 - tp: 241.0000 - fp: 38.0000 - tn: 268.0000 - fn: 56.0000 - accuracy: 0.8441 - precision: 0.8638 - recall: 0.8114 - auc: 0.9056 - val_loss: 0.4117 - val_tp: 20.0000 - val_fp: 5.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8438 - val_precision: 0.8000 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 40/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.4124 - tp: 231.0000 - fp: 38.0000 - tn: 268.0000 - fn: 66.0000 - accuracy: 0.8275 - precision: 0.8587 - recall: 0.7778 - auc: 0.8911 - val_loss: 0.4079 - val_tp: 20.0000 - val_fp: 5.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8438 - val_precision: 0.8000 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 41/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.4158 - tp: 234.0000 - fp: 45.0000 - tn: 261.0000 - fn: 63.0000 - accuracy: 0.8209 - precision: 0.8387 - recall: 0.7879 - auc: 0.8980 - val_loss: 0.4043 - val_tp: 20.0000 - val_fp: 5.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8438 - val_precision: 0.8000 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 42/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.3941 - tp: 243.0000 - fp: 36.0000 - tn: 270.0000 - fn: 54.0000 - accuracy: 0.8507 - precision: 0.8710 - recall: 0.8182 - auc: 0.9139 - val_loss: 0.4008 - val_tp: 20.0000 - val_fp: 5.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8438 - val_precision: 0.8000 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 43/400\n","name":"stdout"},{"output_type":"stream","text":"1/1 [==============================] - 0s 26ms/step - loss: 0.3776 - tp: 241.0000 - fp: 37.0000 - tn: 269.0000 - fn: 56.0000 - accuracy: 0.8458 - precision: 0.8669 - recall: 0.8114 - auc: 0.9118 - val_loss: 0.3978 - val_tp: 20.0000 - val_fp: 5.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8438 - val_precision: 0.8000 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 44/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.3673 - tp: 233.0000 - fp: 28.0000 - tn: 278.0000 - fn: 64.0000 - accuracy: 0.8474 - precision: 0.8927 - recall: 0.7845 - auc: 0.9195 - val_loss: 0.3946 - val_tp: 20.0000 - val_fp: 5.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8438 - val_precision: 0.8000 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 45/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.3754 - tp: 239.0000 - fp: 35.0000 - tn: 271.0000 - fn: 58.0000 - accuracy: 0.8458 - precision: 0.8723 - recall: 0.8047 - auc: 0.9145 - val_loss: 0.3912 - val_tp: 20.0000 - val_fp: 4.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8333 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 46/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.3538 - tp: 239.0000 - fp: 29.0000 - tn: 277.0000 - fn: 58.0000 - accuracy: 0.8557 - precision: 0.8918 - recall: 0.8047 - auc: 0.9298 - val_loss: 0.3877 - val_tp: 20.0000 - val_fp: 4.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8333 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 47/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.3906 - tp: 236.0000 - fp: 35.0000 - tn: 271.0000 - fn: 61.0000 - accuracy: 0.8408 - precision: 0.8708 - recall: 0.7946 - auc: 0.9125 - val_loss: 0.3839 - val_tp: 20.0000 - val_fp: 4.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8333 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 48/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.3530 - tp: 249.0000 - fp: 32.0000 - tn: 274.0000 - fn: 48.0000 - accuracy: 0.8673 - precision: 0.8861 - recall: 0.8384 - auc: 0.9288 - val_loss: 0.3803 - val_tp: 20.0000 - val_fp: 4.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8333 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 49/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.3653 - tp: 237.0000 - fp: 30.0000 - tn: 276.0000 - fn: 60.0000 - accuracy: 0.8507 - precision: 0.8876 - recall: 0.7980 - auc: 0.9194 - val_loss: 0.3769 - val_tp: 20.0000 - val_fp: 4.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8333 - val_recall: 1.0000 - val_auc: 0.9938\nEpoch 50/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.3587 - tp: 242.0000 - fp: 36.0000 - tn: 270.0000 - fn: 55.0000 - accuracy: 0.8491 - precision: 0.8705 - recall: 0.8148 - auc: 0.9196 - val_loss: 0.3738 - val_tp: 20.0000 - val_fp: 4.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8333 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 51/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.3527 - tp: 246.0000 - fp: 22.0000 - tn: 284.0000 - fn: 51.0000 - accuracy: 0.8789 - precision: 0.9179 - recall: 0.8283 - auc: 0.9240 - val_loss: 0.3709 - val_tp: 20.0000 - val_fp: 4.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8333 - val_recall: 1.0000 - val_auc: 0.9937\nEpoch 52/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.3472 - tp: 245.0000 - fp: 21.0000 - tn: 285.0000 - fn: 52.0000 - accuracy: 0.8789 - precision: 0.9211 - recall: 0.8249 - auc: 0.9371 - val_loss: 0.3681 - val_tp: 20.0000 - val_fp: 4.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8333 - val_recall: 1.0000 - val_auc: 0.9937\nEpoch 53/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.3804 - tp: 240.0000 - fp: 26.0000 - tn: 280.0000 - fn: 57.0000 - accuracy: 0.8624 - precision: 0.9023 - recall: 0.8081 - auc: 0.9126 - val_loss: 0.3652 - val_tp: 20.0000 - val_fp: 4.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8333 - val_recall: 1.0000 - val_auc: 0.9937\nEpoch 54/400\n1/1 [==============================] - 0s 29ms/step - loss: 0.3291 - tp: 244.0000 - fp: 32.0000 - tn: 274.0000 - fn: 53.0000 - accuracy: 0.8590 - precision: 0.8841 - recall: 0.8215 - auc: 0.9382 - val_loss: 0.3617 - val_tp: 20.0000 - val_fp: 4.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8333 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 55/400\n1/1 [==============================] - 0s 29ms/step - loss: 0.3349 - tp: 249.0000 - fp: 24.0000 - tn: 282.0000 - fn: 48.0000 - accuracy: 0.8806 - precision: 0.9121 - recall: 0.8384 - auc: 0.9300 - val_loss: 0.3582 - val_tp: 20.0000 - val_fp: 4.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8333 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 56/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.3347 - tp: 248.0000 - fp: 28.0000 - tn: 278.0000 - fn: 49.0000 - accuracy: 0.8723 - precision: 0.8986 - recall: 0.8350 - auc: 0.9316 - val_loss: 0.3547 - val_tp: 20.0000 - val_fp: 4.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8333 - val_recall: 1.0000 - val_auc: 0.9979\nEpoch 57/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.3282 - tp: 247.0000 - fp: 34.0000 - tn: 272.0000 - fn: 50.0000 - accuracy: 0.8607 - precision: 0.8790 - recall: 0.8316 - auc: 0.9331 - val_loss: 0.3512 - val_tp: 20.0000 - val_fp: 4.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8333 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 58/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.3413 - tp: 248.0000 - fp: 23.0000 - tn: 283.0000 - fn: 49.0000 - accuracy: 0.8806 - precision: 0.9151 - recall: 0.8350 - auc: 0.9297 - val_loss: 0.3478 - val_tp: 20.0000 - val_fp: 4.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8333 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 59/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.3273 - tp: 252.0000 - fp: 28.0000 - tn: 278.0000 - fn: 45.0000 - accuracy: 0.8789 - precision: 0.9000 - recall: 0.8485 - auc: 0.9339 - val_loss: 0.3444 - val_tp: 20.0000 - val_fp: 4.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8333 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 60/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.3068 - tp: 255.0000 - fp: 26.0000 - tn: 280.0000 - fn: 42.0000 - accuracy: 0.8872 - precision: 0.9075 - recall: 0.8586 - auc: 0.9414 - val_loss: 0.3414 - val_tp: 20.0000 - val_fp: 4.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8333 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 61/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.3463 - tp: 251.0000 - fp: 32.0000 - tn: 274.0000 - fn: 46.0000 - accuracy: 0.8706 - precision: 0.8869 - recall: 0.8451 - auc: 0.9275 - val_loss: 0.3383 - val_tp: 20.0000 - val_fp: 4.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8333 - val_recall: 1.0000 - val_auc: 0.9979\nEpoch 62/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.3013 - tp: 257.0000 - fp: 29.0000 - tn: 277.0000 - fn: 40.0000 - accuracy: 0.8856 - precision: 0.8986 - recall: 0.8653 - auc: 0.9454 - val_loss: 0.3353 - val_tp: 20.0000 - val_fp: 3.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9062 - val_precision: 0.8696 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 63/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.3419 - tp: 247.0000 - fp: 32.0000 - tn: 274.0000 - fn: 50.0000 - accuracy: 0.8640 - precision: 0.8853 - recall: 0.8316 - auc: 0.9268 - val_loss: 0.3318 - val_tp: 20.0000 - val_fp: 3.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9062 - val_precision: 0.8696 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 64/400\n","name":"stdout"},{"output_type":"stream","text":"1/1 [==============================] - 0s 31ms/step - loss: 0.3396 - tp: 245.0000 - fp: 29.0000 - tn: 277.0000 - fn: 52.0000 - accuracy: 0.8657 - precision: 0.8942 - recall: 0.8249 - auc: 0.9261 - val_loss: 0.3288 - val_tp: 20.0000 - val_fp: 3.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9062 - val_precision: 0.8696 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 65/400\n1/1 [==============================] - 0s 29ms/step - loss: 0.3115 - tp: 246.0000 - fp: 25.0000 - tn: 281.0000 - fn: 51.0000 - accuracy: 0.8740 - precision: 0.9077 - recall: 0.8283 - auc: 0.9401 - val_loss: 0.3260 - val_tp: 20.0000 - val_fp: 3.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9062 - val_precision: 0.8696 - val_recall: 1.0000 - val_auc: 0.9937\nEpoch 66/400\n1/1 [==============================] - 0s 30ms/step - loss: 0.3143 - tp: 248.0000 - fp: 21.0000 - tn: 285.0000 - fn: 49.0000 - accuracy: 0.8839 - precision: 0.9219 - recall: 0.8350 - auc: 0.9354 - val_loss: 0.3236 - val_tp: 20.0000 - val_fp: 3.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9062 - val_precision: 0.8696 - val_recall: 1.0000 - val_auc: 0.9937\nEpoch 67/400\n1/1 [==============================] - 0s 38ms/step - loss: 0.3197 - tp: 246.0000 - fp: 26.0000 - tn: 280.0000 - fn: 51.0000 - accuracy: 0.8723 - precision: 0.9044 - recall: 0.8283 - auc: 0.9379 - val_loss: 0.3210 - val_tp: 20.0000 - val_fp: 3.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9062 - val_precision: 0.8696 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 68/400\n1/1 [==============================] - 0s 29ms/step - loss: 0.2892 - tp: 258.0000 - fp: 24.0000 - tn: 282.0000 - fn: 39.0000 - accuracy: 0.8955 - precision: 0.9149 - recall: 0.8687 - auc: 0.9492 - val_loss: 0.3187 - val_tp: 20.0000 - val_fp: 3.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9062 - val_precision: 0.8696 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 69/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.2821 - tp: 253.0000 - fp: 16.0000 - tn: 290.0000 - fn: 44.0000 - accuracy: 0.9005 - precision: 0.9405 - recall: 0.8519 - auc: 0.9493 - val_loss: 0.3163 - val_tp: 20.0000 - val_fp: 3.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9062 - val_precision: 0.8696 - val_recall: 1.0000 - val_auc: 0.9937\nEpoch 70/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.2988 - tp: 250.0000 - fp: 30.0000 - tn: 276.0000 - fn: 47.0000 - accuracy: 0.8723 - precision: 0.8929 - recall: 0.8418 - auc: 0.9441 - val_loss: 0.3137 - val_tp: 20.0000 - val_fp: 3.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9062 - val_precision: 0.8696 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 71/400\n1/1 [==============================] - 0s 29ms/step - loss: 0.3030 - tp: 248.0000 - fp: 17.0000 - tn: 289.0000 - fn: 49.0000 - accuracy: 0.8905 - precision: 0.9358 - recall: 0.8350 - auc: 0.9409 - val_loss: 0.3113 - val_tp: 20.0000 - val_fp: 3.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9062 - val_precision: 0.8696 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 72/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.3118 - tp: 250.0000 - fp: 19.0000 - tn: 287.0000 - fn: 47.0000 - accuracy: 0.8905 - precision: 0.9294 - recall: 0.8418 - auc: 0.9427 - val_loss: 0.3091 - val_tp: 20.0000 - val_fp: 3.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9062 - val_precision: 0.8696 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 73/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.3029 - tp: 255.0000 - fp: 22.0000 - tn: 284.0000 - fn: 42.0000 - accuracy: 0.8939 - precision: 0.9206 - recall: 0.8586 - auc: 0.9403 - val_loss: 0.3072 - val_tp: 20.0000 - val_fp: 3.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9062 - val_precision: 0.8696 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 74/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.2864 - tp: 259.0000 - fp: 27.0000 - tn: 279.0000 - fn: 38.0000 - accuracy: 0.8922 - precision: 0.9056 - recall: 0.8721 - auc: 0.9479 - val_loss: 0.3054 - val_tp: 20.0000 - val_fp: 3.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9062 - val_precision: 0.8696 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 75/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.2782 - tp: 253.0000 - fp: 24.0000 - tn: 282.0000 - fn: 44.0000 - accuracy: 0.8872 - precision: 0.9134 - recall: 0.8519 - auc: 0.9545 - val_loss: 0.3029 - val_tp: 20.0000 - val_fp: 3.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9062 - val_precision: 0.8696 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 76/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.2923 - tp: 256.0000 - fp: 24.0000 - tn: 282.0000 - fn: 41.0000 - accuracy: 0.8922 - precision: 0.9143 - recall: 0.8620 - auc: 0.9440 - val_loss: 0.3002 - val_tp: 20.0000 - val_fp: 3.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9062 - val_precision: 0.8696 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 77/400\n1/1 [==============================] - 0s 30ms/step - loss: 0.3205 - tp: 254.0000 - fp: 27.0000 - tn: 279.0000 - fn: 43.0000 - accuracy: 0.8839 - precision: 0.9039 - recall: 0.8552 - auc: 0.9383 - val_loss: 0.2974 - val_tp: 20.0000 - val_fp: 3.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9062 - val_precision: 0.8696 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 78/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.2828 - tp: 262.0000 - fp: 23.0000 - tn: 283.0000 - fn: 35.0000 - accuracy: 0.9038 - precision: 0.9193 - recall: 0.8822 - auc: 0.9485 - val_loss: 0.2948 - val_tp: 20.0000 - val_fp: 3.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9062 - val_precision: 0.8696 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 79/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.2929 - tp: 254.0000 - fp: 22.0000 - tn: 284.0000 - fn: 43.0000 - accuracy: 0.8922 - precision: 0.9203 - recall: 0.8552 - auc: 0.9449 - val_loss: 0.2916 - val_tp: 20.0000 - val_fp: 3.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9062 - val_precision: 0.8696 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 80/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.2872 - tp: 259.0000 - fp: 25.0000 - tn: 281.0000 - fn: 38.0000 - accuracy: 0.8955 - precision: 0.9120 - recall: 0.8721 - auc: 0.9471 - val_loss: 0.2886 - val_tp: 20.0000 - val_fp: 3.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9062 - val_precision: 0.8696 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 81/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.2641 - tp: 257.0000 - fp: 22.0000 - tn: 284.0000 - fn: 40.0000 - accuracy: 0.8972 - precision: 0.9211 - recall: 0.8653 - auc: 0.9545 - val_loss: 0.2858 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 82/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.3073 - tp: 254.0000 - fp: 22.0000 - tn: 284.0000 - fn: 43.0000 - accuracy: 0.8922 - precision: 0.9203 - recall: 0.8552 - auc: 0.9370 - val_loss: 0.2828 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 83/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.2620 - tp: 264.0000 - fp: 19.0000 - tn: 287.0000 - fn: 33.0000 - accuracy: 0.9138 - precision: 0.9329 - recall: 0.8889 - auc: 0.9569 - val_loss: 0.2800 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 84/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.2725 - tp: 259.0000 - fp: 20.0000 - tn: 286.0000 - fn: 38.0000 - accuracy: 0.9038 - precision: 0.9283 - recall: 0.8721 - auc: 0.9509 - val_loss: 0.2770 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 85/400\n","name":"stdout"},{"output_type":"stream","text":"1/1 [==============================] - 0s 27ms/step - loss: 0.2368 - tp: 263.0000 - fp: 16.0000 - tn: 290.0000 - fn: 34.0000 - accuracy: 0.9171 - precision: 0.9427 - recall: 0.8855 - auc: 0.9660 - val_loss: 0.2739 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 86/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.2588 - tp: 259.0000 - fp: 19.0000 - tn: 287.0000 - fn: 38.0000 - accuracy: 0.9055 - precision: 0.9317 - recall: 0.8721 - auc: 0.9550 - val_loss: 0.2710 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 87/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.2593 - tp: 261.0000 - fp: 24.0000 - tn: 282.0000 - fn: 36.0000 - accuracy: 0.9005 - precision: 0.9158 - recall: 0.8788 - auc: 0.9594 - val_loss: 0.2686 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 88/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.2598 - tp: 263.0000 - fp: 23.0000 - tn: 283.0000 - fn: 34.0000 - accuracy: 0.9055 - precision: 0.9196 - recall: 0.8855 - auc: 0.9562 - val_loss: 0.2668 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 89/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.2577 - tp: 259.0000 - fp: 22.0000 - tn: 284.0000 - fn: 38.0000 - accuracy: 0.9005 - precision: 0.9217 - recall: 0.8721 - auc: 0.9557 - val_loss: 0.2650 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 90/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.2655 - tp: 253.0000 - fp: 21.0000 - tn: 285.0000 - fn: 44.0000 - accuracy: 0.8922 - precision: 0.9234 - recall: 0.8519 - auc: 0.9562 - val_loss: 0.2629 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 91/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.2618 - tp: 256.0000 - fp: 29.0000 - tn: 277.0000 - fn: 41.0000 - accuracy: 0.8839 - precision: 0.8982 - recall: 0.8620 - auc: 0.9557 - val_loss: 0.2612 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 92/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.2301 - tp: 269.0000 - fp: 24.0000 - tn: 282.0000 - fn: 28.0000 - accuracy: 0.9138 - precision: 0.9181 - recall: 0.9057 - auc: 0.9675 - val_loss: 0.2591 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9875\nEpoch 93/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.2539 - tp: 263.0000 - fp: 26.0000 - tn: 280.0000 - fn: 34.0000 - accuracy: 0.9005 - precision: 0.9100 - recall: 0.8855 - auc: 0.9565 - val_loss: 0.2572 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9875\nEpoch 94/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.2568 - tp: 260.0000 - fp: 22.0000 - tn: 284.0000 - fn: 37.0000 - accuracy: 0.9022 - precision: 0.9220 - recall: 0.8754 - auc: 0.9582 - val_loss: 0.2554 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9875\nEpoch 95/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.2585 - tp: 262.0000 - fp: 22.0000 - tn: 284.0000 - fn: 35.0000 - accuracy: 0.9055 - precision: 0.9225 - recall: 0.8822 - auc: 0.9566 - val_loss: 0.2534 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9875\nEpoch 96/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.2575 - tp: 257.0000 - fp: 19.0000 - tn: 287.0000 - fn: 40.0000 - accuracy: 0.9022 - precision: 0.9312 - recall: 0.8653 - auc: 0.9572 - val_loss: 0.2519 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9875\nEpoch 97/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.2620 - tp: 261.0000 - fp: 20.0000 - tn: 286.0000 - fn: 36.0000 - accuracy: 0.9071 - precision: 0.9288 - recall: 0.8788 - auc: 0.9547 - val_loss: 0.2502 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9896\nEpoch 98/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.2443 - tp: 270.0000 - fp: 19.0000 - tn: 287.0000 - fn: 27.0000 - accuracy: 0.9237 - precision: 0.9343 - recall: 0.9091 - auc: 0.9639 - val_loss: 0.2487 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 99/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.2208 - tp: 268.0000 - fp: 14.0000 - tn: 292.0000 - fn: 29.0000 - accuracy: 0.9287 - precision: 0.9504 - recall: 0.9024 - auc: 0.9695 - val_loss: 0.2472 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 100/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.2253 - tp: 265.0000 - fp: 14.0000 - tn: 292.0000 - fn: 32.0000 - accuracy: 0.9237 - precision: 0.9498 - recall: 0.8923 - auc: 0.9654 - val_loss: 0.2454 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 101/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.2418 - tp: 261.0000 - fp: 24.0000 - tn: 282.0000 - fn: 36.0000 - accuracy: 0.9005 - precision: 0.9158 - recall: 0.8788 - auc: 0.9648 - val_loss: 0.2432 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 102/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.2853 - tp: 265.0000 - fp: 25.0000 - tn: 281.0000 - fn: 32.0000 - accuracy: 0.9055 - precision: 0.9138 - recall: 0.8923 - auc: 0.9474 - val_loss: 0.2404 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 103/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.2407 - tp: 264.0000 - fp: 22.0000 - tn: 284.0000 - fn: 33.0000 - accuracy: 0.9088 - precision: 0.9231 - recall: 0.8889 - auc: 0.9623 - val_loss: 0.2366 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 104/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.2429 - tp: 259.0000 - fp: 23.0000 - tn: 283.0000 - fn: 38.0000 - accuracy: 0.8988 - precision: 0.9184 - recall: 0.8721 - auc: 0.9643 - val_loss: 0.2329 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9896\nEpoch 105/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.2280 - tp: 263.0000 - fp: 15.0000 - tn: 291.0000 - fn: 34.0000 - accuracy: 0.9187 - precision: 0.9460 - recall: 0.8855 - auc: 0.9671 - val_loss: 0.2299 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9875\nEpoch 106/400\n","name":"stdout"},{"output_type":"stream","text":"1/1 [==============================] - 0s 25ms/step - loss: 0.2327 - tp: 268.0000 - fp: 18.0000 - tn: 288.0000 - fn: 29.0000 - accuracy: 0.9221 - precision: 0.9371 - recall: 0.9024 - auc: 0.9659 - val_loss: 0.2268 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9875\nEpoch 107/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.2537 - tp: 258.0000 - fp: 21.0000 - tn: 285.0000 - fn: 39.0000 - accuracy: 0.9005 - precision: 0.9247 - recall: 0.8687 - auc: 0.9593 - val_loss: 0.2241 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9875\nEpoch 108/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.2398 - tp: 258.0000 - fp: 22.0000 - tn: 284.0000 - fn: 39.0000 - accuracy: 0.8988 - precision: 0.9214 - recall: 0.8687 - auc: 0.9624 - val_loss: 0.2220 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9875\nEpoch 109/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.2310 - tp: 264.0000 - fp: 21.0000 - tn: 285.0000 - fn: 33.0000 - accuracy: 0.9104 - precision: 0.9263 - recall: 0.8889 - auc: 0.9664 - val_loss: 0.2198 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9896\nEpoch 110/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.2320 - tp: 267.0000 - fp: 15.0000 - tn: 291.0000 - fn: 30.0000 - accuracy: 0.9254 - precision: 0.9468 - recall: 0.8990 - auc: 0.9641 - val_loss: 0.2169 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 111/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.2427 - tp: 262.0000 - fp: 17.0000 - tn: 289.0000 - fn: 35.0000 - accuracy: 0.9138 - precision: 0.9391 - recall: 0.8822 - auc: 0.9612 - val_loss: 0.2140 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 112/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.2277 - tp: 266.0000 - fp: 17.0000 - tn: 289.0000 - fn: 31.0000 - accuracy: 0.9204 - precision: 0.9399 - recall: 0.8956 - auc: 0.9635 - val_loss: 0.2122 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 113/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.2178 - tp: 271.0000 - fp: 14.0000 - tn: 292.0000 - fn: 26.0000 - accuracy: 0.9337 - precision: 0.9509 - recall: 0.9125 - auc: 0.9696 - val_loss: 0.2103 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 114/400\n1/1 [==============================] - 0s 46ms/step - loss: 0.1927 - tp: 270.0000 - fp: 15.0000 - tn: 291.0000 - fn: 27.0000 - accuracy: 0.9303 - precision: 0.9474 - recall: 0.9091 - auc: 0.9795 - val_loss: 0.2087 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 115/400\n1/1 [==============================] - 0s 30ms/step - loss: 0.2152 - tp: 267.0000 - fp: 20.0000 - tn: 286.0000 - fn: 30.0000 - accuracy: 0.9171 - precision: 0.9303 - recall: 0.8990 - auc: 0.9718 - val_loss: 0.2070 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 116/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.1981 - tp: 274.0000 - fp: 16.0000 - tn: 290.0000 - fn: 23.0000 - accuracy: 0.9353 - precision: 0.9448 - recall: 0.9226 - auc: 0.9760 - val_loss: 0.2051 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 117/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.2267 - tp: 272.0000 - fp: 15.0000 - tn: 291.0000 - fn: 25.0000 - accuracy: 0.9337 - precision: 0.9477 - recall: 0.9158 - auc: 0.9643 - val_loss: 0.2032 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 118/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.2132 - tp: 264.0000 - fp: 21.0000 - tn: 285.0000 - fn: 33.0000 - accuracy: 0.9104 - precision: 0.9263 - recall: 0.8889 - auc: 0.9713 - val_loss: 0.2013 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 119/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.2315 - tp: 266.0000 - fp: 23.0000 - tn: 283.0000 - fn: 31.0000 - accuracy: 0.9104 - precision: 0.9204 - recall: 0.8956 - auc: 0.9650 - val_loss: 0.1990 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 120/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1871 - tp: 269.0000 - fp: 12.0000 - tn: 294.0000 - fn: 28.0000 - accuracy: 0.9337 - precision: 0.9573 - recall: 0.9057 - auc: 0.9808 - val_loss: 0.1968 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9875\nEpoch 121/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.2249 - tp: 269.0000 - fp: 24.0000 - tn: 282.0000 - fn: 28.0000 - accuracy: 0.9138 - precision: 0.9181 - recall: 0.9057 - auc: 0.9661 - val_loss: 0.1949 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9875\nEpoch 122/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.2012 - tp: 267.0000 - fp: 13.0000 - tn: 293.0000 - fn: 30.0000 - accuracy: 0.9287 - precision: 0.9536 - recall: 0.8990 - auc: 0.9733 - val_loss: 0.1928 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9875\nEpoch 123/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.2196 - tp: 267.0000 - fp: 22.0000 - tn: 284.0000 - fn: 30.0000 - accuracy: 0.9138 - precision: 0.9239 - recall: 0.8990 - auc: 0.9677 - val_loss: 0.1912 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9875\nEpoch 124/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.2287 - tp: 267.0000 - fp: 14.0000 - tn: 292.0000 - fn: 30.0000 - accuracy: 0.9270 - precision: 0.9502 - recall: 0.8990 - auc: 0.9648 - val_loss: 0.1903 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 125/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.2175 - tp: 267.0000 - fp: 18.0000 - tn: 288.0000 - fn: 30.0000 - accuracy: 0.9204 - precision: 0.9368 - recall: 0.8990 - auc: 0.9673 - val_loss: 0.1894 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 126/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.2184 - tp: 271.0000 - fp: 13.0000 - tn: 293.0000 - fn: 26.0000 - accuracy: 0.9353 - precision: 0.9542 - recall: 0.9125 - auc: 0.9657 - val_loss: 0.1883 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 127/400\n","name":"stdout"},{"output_type":"stream","text":"1/1 [==============================] - 0s 25ms/step - loss: 0.2091 - tp: 270.0000 - fp: 18.0000 - tn: 288.0000 - fn: 27.0000 - accuracy: 0.9254 - precision: 0.9375 - recall: 0.9091 - auc: 0.9721 - val_loss: 0.1857 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 128/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.2029 - tp: 271.0000 - fp: 14.0000 - tn: 292.0000 - fn: 26.0000 - accuracy: 0.9337 - precision: 0.9509 - recall: 0.9125 - auc: 0.9711 - val_loss: 0.1826 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 129/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1955 - tp: 270.0000 - fp: 11.0000 - tn: 295.0000 - fn: 27.0000 - accuracy: 0.9370 - precision: 0.9609 - recall: 0.9091 - auc: 0.9740 - val_loss: 0.1787 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 130/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1915 - tp: 273.0000 - fp: 14.0000 - tn: 292.0000 - fn: 24.0000 - accuracy: 0.9370 - precision: 0.9512 - recall: 0.9192 - auc: 0.9762 - val_loss: 0.1763 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 131/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.1927 - tp: 271.0000 - fp: 15.0000 - tn: 291.0000 - fn: 26.0000 - accuracy: 0.9320 - precision: 0.9476 - recall: 0.9125 - auc: 0.9763 - val_loss: 0.1741 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 132/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.1783 - tp: 276.0000 - fp: 12.0000 - tn: 294.0000 - fn: 21.0000 - accuracy: 0.9453 - precision: 0.9583 - recall: 0.9293 - auc: 0.9777 - val_loss: 0.1715 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 133/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.2059 - tp: 268.0000 - fp: 22.0000 - tn: 284.0000 - fn: 29.0000 - accuracy: 0.9154 - precision: 0.9241 - recall: 0.9024 - auc: 0.9720 - val_loss: 0.1689 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9917\nEpoch 134/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.1802 - tp: 272.0000 - fp: 13.0000 - tn: 293.0000 - fn: 25.0000 - accuracy: 0.9370 - precision: 0.9544 - recall: 0.9158 - auc: 0.9777 - val_loss: 0.1660 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 135/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1743 - tp: 268.0000 - fp: 13.0000 - tn: 293.0000 - fn: 29.0000 - accuracy: 0.9303 - precision: 0.9537 - recall: 0.9024 - auc: 0.9830 - val_loss: 0.1636 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 136/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1958 - tp: 271.0000 - fp: 18.0000 - tn: 288.0000 - fn: 26.0000 - accuracy: 0.9270 - precision: 0.9377 - recall: 0.9125 - auc: 0.9752 - val_loss: 0.1620 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 137/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.1651 - tp: 271.0000 - fp: 12.0000 - tn: 294.0000 - fn: 26.0000 - accuracy: 0.9370 - precision: 0.9576 - recall: 0.9125 - auc: 0.9816 - val_loss: 0.1608 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 138/400\n1/1 [==============================] - 0s 32ms/step - loss: 0.1751 - tp: 272.0000 - fp: 14.0000 - tn: 292.0000 - fn: 25.0000 - accuracy: 0.9353 - precision: 0.9510 - recall: 0.9158 - auc: 0.9809 - val_loss: 0.1586 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 139/400\n1/1 [==============================] - 0s 45ms/step - loss: 0.1724 - tp: 275.0000 - fp: 12.0000 - tn: 294.0000 - fn: 22.0000 - accuracy: 0.9436 - precision: 0.9582 - recall: 0.9259 - auc: 0.9821 - val_loss: 0.1568 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 140/400\n1/1 [==============================] - 0s 42ms/step - loss: 0.1721 - tp: 277.0000 - fp: 15.0000 - tn: 291.0000 - fn: 20.0000 - accuracy: 0.9420 - precision: 0.9486 - recall: 0.9327 - auc: 0.9804 - val_loss: 0.1554 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 141/400\n1/1 [==============================] - 0s 46ms/step - loss: 0.1942 - tp: 271.0000 - fp: 13.0000 - tn: 293.0000 - fn: 26.0000 - accuracy: 0.9353 - precision: 0.9542 - recall: 0.9125 - auc: 0.9754 - val_loss: 0.1538 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 142/400\n1/1 [==============================] - 0s 50ms/step - loss: 0.1725 - tp: 271.0000 - fp: 15.0000 - tn: 291.0000 - fn: 26.0000 - accuracy: 0.9320 - precision: 0.9476 - recall: 0.9125 - auc: 0.9813 - val_loss: 0.1525 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 143/400\n1/1 [==============================] - 0s 40ms/step - loss: 0.1847 - tp: 273.0000 - fp: 15.0000 - tn: 291.0000 - fn: 24.0000 - accuracy: 0.9353 - precision: 0.9479 - recall: 0.9192 - auc: 0.9771 - val_loss: 0.1513 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 144/400\n1/1 [==============================] - 0s 40ms/step - loss: 0.1779 - tp: 273.0000 - fp: 12.0000 - tn: 294.0000 - fn: 24.0000 - accuracy: 0.9403 - precision: 0.9579 - recall: 0.9192 - auc: 0.9787 - val_loss: 0.1503 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 145/400\n1/1 [==============================] - 0s 47ms/step - loss: 0.1787 - tp: 274.0000 - fp: 14.0000 - tn: 292.0000 - fn: 23.0000 - accuracy: 0.9386 - precision: 0.9514 - recall: 0.9226 - auc: 0.9788 - val_loss: 0.1466 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 146/400\n1/1 [==============================] - 0s 36ms/step - loss: 0.1828 - tp: 277.0000 - fp: 14.0000 - tn: 292.0000 - fn: 20.0000 - accuracy: 0.9436 - precision: 0.9519 - recall: 0.9327 - auc: 0.9750 - val_loss: 0.1443 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 147/400\n1/1 [==============================] - 0s 37ms/step - loss: 0.1883 - tp: 275.0000 - fp: 18.0000 - tn: 288.0000 - fn: 22.0000 - accuracy: 0.9337 - precision: 0.9386 - recall: 0.9259 - auc: 0.9774 - val_loss: 0.1424 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 148/400\n","name":"stdout"},{"output_type":"stream","text":"1/1 [==============================] - 0s 34ms/step - loss: 0.1724 - tp: 271.0000 - fp: 10.0000 - tn: 296.0000 - fn: 26.0000 - accuracy: 0.9403 - precision: 0.9644 - recall: 0.9125 - auc: 0.9817 - val_loss: 0.1423 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 149/400\n1/1 [==============================] - 0s 35ms/step - loss: 0.1460 - tp: 280.0000 - fp: 12.0000 - tn: 294.0000 - fn: 17.0000 - accuracy: 0.9519 - precision: 0.9589 - recall: 0.9428 - auc: 0.9873 - val_loss: 0.1428 - val_tp: 19.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 1.0000 - val_accuracy: 0.9375 - val_precision: 0.9500 - val_recall: 0.9500 - val_auc: 0.9917\nEpoch 150/400\n1/1 [==============================] - 0s 41ms/step - loss: 0.1519 - tp: 276.0000 - fp: 13.0000 - tn: 293.0000 - fn: 21.0000 - accuracy: 0.9436 - precision: 0.9550 - recall: 0.9293 - auc: 0.9873 - val_loss: 0.1419 - val_tp: 19.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 1.0000 - val_accuracy: 0.9375 - val_precision: 0.9500 - val_recall: 0.9500 - val_auc: 0.9917\nEpoch 151/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1568 - tp: 275.0000 - fp: 13.0000 - tn: 293.0000 - fn: 22.0000 - accuracy: 0.9420 - precision: 0.9549 - recall: 0.9259 - auc: 0.9816 - val_loss: 0.1399 - val_tp: 19.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 1.0000 - val_accuracy: 0.9375 - val_precision: 0.9500 - val_recall: 0.9500 - val_auc: 0.9917\nEpoch 152/400\n1/1 [==============================] - 0s 34ms/step - loss: 0.1730 - tp: 279.0000 - fp: 16.0000 - tn: 290.0000 - fn: 18.0000 - accuracy: 0.9436 - precision: 0.9458 - recall: 0.9394 - auc: 0.9766 - val_loss: 0.1365 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 153/400\n1/1 [==============================] - 0s 39ms/step - loss: 0.1741 - tp: 277.0000 - fp: 18.0000 - tn: 288.0000 - fn: 20.0000 - accuracy: 0.9370 - precision: 0.9390 - recall: 0.9327 - auc: 0.9783 - val_loss: 0.1332 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 154/400\n1/1 [==============================] - 0s 33ms/step - loss: 0.1491 - tp: 279.0000 - fp: 10.0000 - tn: 296.0000 - fn: 18.0000 - accuracy: 0.9536 - precision: 0.9654 - recall: 0.9394 - auc: 0.9850 - val_loss: 0.1307 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 155/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1650 - tp: 274.0000 - fp: 7.0000 - tn: 299.0000 - fn: 23.0000 - accuracy: 0.9502 - precision: 0.9751 - recall: 0.9226 - auc: 0.9792 - val_loss: 0.1293 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 156/400\n1/1 [==============================] - 0s 39ms/step - loss: 0.1605 - tp: 283.0000 - fp: 16.0000 - tn: 290.0000 - fn: 14.0000 - accuracy: 0.9502 - precision: 0.9465 - recall: 0.9529 - auc: 0.9823 - val_loss: 0.1277 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 157/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.1534 - tp: 274.0000 - fp: 11.0000 - tn: 295.0000 - fn: 23.0000 - accuracy: 0.9436 - precision: 0.9614 - recall: 0.9226 - auc: 0.9828 - val_loss: 0.1281 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 158/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1749 - tp: 274.0000 - fp: 13.0000 - tn: 293.0000 - fn: 23.0000 - accuracy: 0.9403 - precision: 0.9547 - recall: 0.9226 - auc: 0.9803 - val_loss: 0.1260 - val_tp: 20.0000 - val_fp: 2.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 159/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1327 - tp: 282.0000 - fp: 10.0000 - tn: 296.0000 - fn: 15.0000 - accuracy: 0.9585 - precision: 0.9658 - recall: 0.9495 - auc: 0.9896 - val_loss: 0.1238 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 160/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1687 - tp: 279.0000 - fp: 9.0000 - tn: 297.0000 - fn: 18.0000 - accuracy: 0.9552 - precision: 0.9688 - recall: 0.9394 - auc: 0.9797 - val_loss: 0.1203 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 161/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1406 - tp: 277.0000 - fp: 9.0000 - tn: 297.0000 - fn: 20.0000 - accuracy: 0.9519 - precision: 0.9685 - recall: 0.9327 - auc: 0.9854 - val_loss: 0.1186 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 162/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1613 - tp: 277.0000 - fp: 12.0000 - tn: 294.0000 - fn: 20.0000 - accuracy: 0.9469 - precision: 0.9585 - recall: 0.9327 - auc: 0.9808 - val_loss: 0.1176 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 163/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.1452 - tp: 278.0000 - fp: 8.0000 - tn: 298.0000 - fn: 19.0000 - accuracy: 0.9552 - precision: 0.9720 - recall: 0.9360 - auc: 0.9830 - val_loss: 0.1166 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 164/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.1529 - tp: 276.0000 - fp: 12.0000 - tn: 294.0000 - fn: 21.0000 - accuracy: 0.9453 - precision: 0.9583 - recall: 0.9293 - auc: 0.9835 - val_loss: 0.1153 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 165/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.1202 - tp: 283.0000 - fp: 9.0000 - tn: 297.0000 - fn: 14.0000 - accuracy: 0.9619 - precision: 0.9692 - recall: 0.9529 - auc: 0.9919 - val_loss: 0.1143 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 0.9979\nEpoch 166/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.1213 - tp: 282.0000 - fp: 8.0000 - tn: 298.0000 - fn: 15.0000 - accuracy: 0.9619 - precision: 0.9724 - recall: 0.9495 - auc: 0.9894 - val_loss: 0.1123 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 167/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.1497 - tp: 277.0000 - fp: 12.0000 - tn: 294.0000 - fn: 20.0000 - accuracy: 0.9469 - precision: 0.9585 - recall: 0.9327 - auc: 0.9852 - val_loss: 0.1102 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 168/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.1618 - tp: 279.0000 - fp: 12.0000 - tn: 294.0000 - fn: 18.0000 - accuracy: 0.9502 - precision: 0.9588 - recall: 0.9394 - auc: 0.9809 - val_loss: 0.1080 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 169/400\n","name":"stdout"},{"output_type":"stream","text":"1/1 [==============================] - 0s 25ms/step - loss: 0.1396 - tp: 283.0000 - fp: 13.0000 - tn: 293.0000 - fn: 14.0000 - accuracy: 0.9552 - precision: 0.9561 - recall: 0.9529 - auc: 0.9869 - val_loss: 0.1056 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 170/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1315 - tp: 284.0000 - fp: 11.0000 - tn: 295.0000 - fn: 13.0000 - accuracy: 0.9602 - precision: 0.9627 - recall: 0.9562 - auc: 0.9869 - val_loss: 0.1038 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 171/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1288 - tp: 282.0000 - fp: 12.0000 - tn: 294.0000 - fn: 15.0000 - accuracy: 0.9552 - precision: 0.9592 - recall: 0.9495 - auc: 0.9898 - val_loss: 0.1026 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 172/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.1237 - tp: 282.0000 - fp: 7.0000 - tn: 299.0000 - fn: 15.0000 - accuracy: 0.9635 - precision: 0.9758 - recall: 0.9495 - auc: 0.9891 - val_loss: 0.1016 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 173/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.1350 - tp: 284.0000 - fp: 14.0000 - tn: 292.0000 - fn: 13.0000 - accuracy: 0.9552 - precision: 0.9530 - recall: 0.9562 - auc: 0.9868 - val_loss: 0.1016 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 174/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1199 - tp: 282.0000 - fp: 7.0000 - tn: 299.0000 - fn: 15.0000 - accuracy: 0.9635 - precision: 0.9758 - recall: 0.9495 - auc: 0.9898 - val_loss: 0.0997 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 175/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1271 - tp: 282.0000 - fp: 10.0000 - tn: 296.0000 - fn: 15.0000 - accuracy: 0.9585 - precision: 0.9658 - recall: 0.9495 - auc: 0.9889 - val_loss: 0.0959 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 176/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1197 - tp: 282.0000 - fp: 7.0000 - tn: 299.0000 - fn: 15.0000 - accuracy: 0.9635 - precision: 0.9758 - recall: 0.9495 - auc: 0.9891 - val_loss: 0.0945 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 177/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.1225 - tp: 282.0000 - fp: 11.0000 - tn: 295.0000 - fn: 15.0000 - accuracy: 0.9569 - precision: 0.9625 - recall: 0.9495 - auc: 0.9899 - val_loss: 0.0940 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 178/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1478 - tp: 281.0000 - fp: 15.0000 - tn: 291.0000 - fn: 16.0000 - accuracy: 0.9486 - precision: 0.9493 - recall: 0.9461 - auc: 0.9831 - val_loss: 0.0928 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 179/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.1461 - tp: 276.0000 - fp: 13.0000 - tn: 293.0000 - fn: 21.0000 - accuracy: 0.9436 - precision: 0.9550 - recall: 0.9293 - auc: 0.9864 - val_loss: 0.0922 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 180/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1640 - tp: 275.0000 - fp: 14.0000 - tn: 292.0000 - fn: 22.0000 - accuracy: 0.9403 - precision: 0.9516 - recall: 0.9259 - auc: 0.9804 - val_loss: 0.0913 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 181/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.1414 - tp: 281.0000 - fp: 11.0000 - tn: 295.0000 - fn: 16.0000 - accuracy: 0.9552 - precision: 0.9623 - recall: 0.9461 - auc: 0.9861 - val_loss: 0.0913 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 182/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.1223 - tp: 282.0000 - fp: 10.0000 - tn: 296.0000 - fn: 15.0000 - accuracy: 0.9585 - precision: 0.9658 - recall: 0.9495 - auc: 0.9884 - val_loss: 0.0924 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 183/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.1276 - tp: 280.0000 - fp: 9.0000 - tn: 297.0000 - fn: 17.0000 - accuracy: 0.9569 - precision: 0.9689 - recall: 0.9428 - auc: 0.9880 - val_loss: 0.0934 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 184/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1442 - tp: 280.0000 - fp: 11.0000 - tn: 295.0000 - fn: 17.0000 - accuracy: 0.9536 - precision: 0.9622 - recall: 0.9428 - auc: 0.9857 - val_loss: 0.0927 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 185/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.1117 - tp: 284.0000 - fp: 9.0000 - tn: 297.0000 - fn: 13.0000 - accuracy: 0.9635 - precision: 0.9693 - recall: 0.9562 - auc: 0.9928 - val_loss: 0.0907 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 186/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0991 - tp: 285.0000 - fp: 9.0000 - tn: 297.0000 - fn: 12.0000 - accuracy: 0.9652 - precision: 0.9694 - recall: 0.9596 - auc: 0.9932 - val_loss: 0.0891 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 187/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.1203 - tp: 281.0000 - fp: 7.0000 - tn: 299.0000 - fn: 16.0000 - accuracy: 0.9619 - precision: 0.9757 - recall: 0.9461 - auc: 0.9909 - val_loss: 0.0876 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 188/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1327 - tp: 280.0000 - fp: 14.0000 - tn: 292.0000 - fn: 17.0000 - accuracy: 0.9486 - precision: 0.9524 - recall: 0.9428 - auc: 0.9882 - val_loss: 0.0868 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 189/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.1004 - tp: 283.0000 - fp: 11.0000 - tn: 295.0000 - fn: 14.0000 - accuracy: 0.9585 - precision: 0.9626 - recall: 0.9529 - auc: 0.9949 - val_loss: 0.0854 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n","name":"stdout"},{"output_type":"stream","text":"Epoch 190/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.1329 - tp: 280.0000 - fp: 12.0000 - tn: 294.0000 - fn: 17.0000 - accuracy: 0.9519 - precision: 0.9589 - recall: 0.9428 - auc: 0.9877 - val_loss: 0.0854 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 191/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.1280 - tp: 279.0000 - fp: 10.0000 - tn: 296.0000 - fn: 18.0000 - accuracy: 0.9536 - precision: 0.9654 - recall: 0.9394 - auc: 0.9903 - val_loss: 0.0869 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 192/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1271 - tp: 282.0000 - fp: 11.0000 - tn: 295.0000 - fn: 15.0000 - accuracy: 0.9569 - precision: 0.9625 - recall: 0.9495 - auc: 0.9885 - val_loss: 0.0912 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 193/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.1123 - tp: 282.0000 - fp: 8.0000 - tn: 298.0000 - fn: 15.0000 - accuracy: 0.9619 - precision: 0.9724 - recall: 0.9495 - auc: 0.9919 - val_loss: 0.0938 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 0.9979\nEpoch 194/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.1341 - tp: 279.0000 - fp: 12.0000 - tn: 294.0000 - fn: 18.0000 - accuracy: 0.9502 - precision: 0.9588 - recall: 0.9394 - auc: 0.9873 - val_loss: 0.0890 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 195/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.1065 - tp: 285.0000 - fp: 9.0000 - tn: 297.0000 - fn: 12.0000 - accuracy: 0.9652 - precision: 0.9694 - recall: 0.9596 - auc: 0.9925 - val_loss: 0.0835 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 196/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1012 - tp: 284.0000 - fp: 6.0000 - tn: 300.0000 - fn: 13.0000 - accuracy: 0.9685 - precision: 0.9793 - recall: 0.9562 - auc: 0.9940 - val_loss: 0.0827 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 197/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.1070 - tp: 285.0000 - fp: 5.0000 - tn: 301.0000 - fn: 12.0000 - accuracy: 0.9718 - precision: 0.9828 - recall: 0.9596 - auc: 0.9910 - val_loss: 0.0829 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 198/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.1038 - tp: 290.0000 - fp: 8.0000 - tn: 298.0000 - fn: 7.0000 - accuracy: 0.9751 - precision: 0.9732 - recall: 0.9764 - auc: 0.9905 - val_loss: 0.0837 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 199/400\n1/1 [==============================] - 0s 40ms/step - loss: 0.1054 - tp: 284.0000 - fp: 10.0000 - tn: 296.0000 - fn: 13.0000 - accuracy: 0.9619 - precision: 0.9660 - recall: 0.9562 - auc: 0.9938 - val_loss: 0.0856 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 200/400\n1/1 [==============================] - 0s 33ms/step - loss: 0.1279 - tp: 286.0000 - fp: 12.0000 - tn: 294.0000 - fn: 11.0000 - accuracy: 0.9619 - precision: 0.9597 - recall: 0.9630 - auc: 0.9867 - val_loss: 0.0894 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 0.9958\nEpoch 201/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.1175 - tp: 281.0000 - fp: 13.0000 - tn: 293.0000 - fn: 16.0000 - accuracy: 0.9519 - precision: 0.9558 - recall: 0.9461 - auc: 0.9900 - val_loss: 0.0892 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 0.9958\nEpoch 202/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1206 - tp: 285.0000 - fp: 8.0000 - tn: 298.0000 - fn: 12.0000 - accuracy: 0.9668 - precision: 0.9727 - recall: 0.9596 - auc: 0.9878 - val_loss: 0.0842 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 203/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.1085 - tp: 282.0000 - fp: 7.0000 - tn: 299.0000 - fn: 15.0000 - accuracy: 0.9635 - precision: 0.9758 - recall: 0.9495 - auc: 0.9905 - val_loss: 0.0809 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 204/400\n1/1 [==============================] - 0s 66ms/step - loss: 0.1263 - tp: 278.0000 - fp: 9.0000 - tn: 297.0000 - fn: 19.0000 - accuracy: 0.9536 - precision: 0.9686 - recall: 0.9360 - auc: 0.9878 - val_loss: 0.0805 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 205/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.1247 - tp: 282.0000 - fp: 13.0000 - tn: 293.0000 - fn: 15.0000 - accuracy: 0.9536 - precision: 0.9559 - recall: 0.9495 - auc: 0.9901 - val_loss: 0.0861 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 206/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.0954 - tp: 282.0000 - fp: 5.0000 - tn: 301.0000 - fn: 15.0000 - accuracy: 0.9668 - precision: 0.9826 - recall: 0.9495 - auc: 0.9939 - val_loss: 0.0918 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 207/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0987 - tp: 285.0000 - fp: 9.0000 - tn: 297.0000 - fn: 12.0000 - accuracy: 0.9652 - precision: 0.9694 - recall: 0.9596 - auc: 0.9929 - val_loss: 0.0892 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 208/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1097 - tp: 281.0000 - fp: 10.0000 - tn: 296.0000 - fn: 16.0000 - accuracy: 0.9569 - precision: 0.9656 - recall: 0.9461 - auc: 0.9920 - val_loss: 0.0809 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 209/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.0920 - tp: 286.0000 - fp: 6.0000 - tn: 300.0000 - fn: 11.0000 - accuracy: 0.9718 - precision: 0.9795 - recall: 0.9630 - auc: 0.9946 - val_loss: 0.0763 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 210/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.0871 - tp: 284.0000 - fp: 9.0000 - tn: 297.0000 - fn: 13.0000 - accuracy: 0.9635 - precision: 0.9693 - recall: 0.9562 - auc: 0.9968 - val_loss: 0.0807 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 211/400\n","name":"stdout"},{"output_type":"stream","text":"1/1 [==============================] - 0s 25ms/step - loss: 0.0945 - tp: 284.0000 - fp: 8.0000 - tn: 298.0000 - fn: 13.0000 - accuracy: 0.9652 - precision: 0.9726 - recall: 0.9562 - auc: 0.9939 - val_loss: 0.0892 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 212/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.0916 - tp: 285.0000 - fp: 5.0000 - tn: 301.0000 - fn: 12.0000 - accuracy: 0.9718 - precision: 0.9828 - recall: 0.9596 - auc: 0.9951 - val_loss: 0.0963 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 213/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0931 - tp: 283.0000 - fp: 6.0000 - tn: 300.0000 - fn: 14.0000 - accuracy: 0.9668 - precision: 0.9792 - recall: 0.9529 - auc: 0.9945 - val_loss: 0.0911 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 214/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.0953 - tp: 283.0000 - fp: 7.0000 - tn: 299.0000 - fn: 14.0000 - accuracy: 0.9652 - precision: 0.9759 - recall: 0.9529 - auc: 0.9933 - val_loss: 0.0824 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 215/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1020 - tp: 286.0000 - fp: 8.0000 - tn: 298.0000 - fn: 11.0000 - accuracy: 0.9685 - precision: 0.9728 - recall: 0.9630 - auc: 0.9908 - val_loss: 0.0750 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 216/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0836 - tp: 290.0000 - fp: 8.0000 - tn: 298.0000 - fn: 7.0000 - accuracy: 0.9751 - precision: 0.9732 - recall: 0.9764 - auc: 0.9962 - val_loss: 0.0741 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 217/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.1221 - tp: 282.0000 - fp: 10.0000 - tn: 296.0000 - fn: 15.0000 - accuracy: 0.9585 - precision: 0.9658 - recall: 0.9495 - auc: 0.9905 - val_loss: 0.0750 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 218/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0834 - tp: 289.0000 - fp: 6.0000 - tn: 300.0000 - fn: 8.0000 - accuracy: 0.9768 - precision: 0.9797 - recall: 0.9731 - auc: 0.9957 - val_loss: 0.0765 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 219/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0727 - tp: 289.0000 - fp: 7.0000 - tn: 299.0000 - fn: 8.0000 - accuracy: 0.9751 - precision: 0.9764 - recall: 0.9731 - auc: 0.9976 - val_loss: 0.0802 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 220/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.1080 - tp: 286.0000 - fp: 6.0000 - tn: 300.0000 - fn: 11.0000 - accuracy: 0.9718 - precision: 0.9795 - recall: 0.9630 - auc: 0.9895 - val_loss: 0.0873 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 0.9958\nEpoch 221/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.0687 - tp: 289.0000 - fp: 7.0000 - tn: 299.0000 - fn: 8.0000 - accuracy: 0.9751 - precision: 0.9764 - recall: 0.9731 - auc: 0.9973 - val_loss: 0.0984 - val_tp: 19.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 1.0000 - val_accuracy: 0.9375 - val_precision: 0.9500 - val_recall: 0.9500 - val_auc: 0.9958\nEpoch 222/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.0884 - tp: 285.0000 - fp: 5.0000 - tn: 301.0000 - fn: 12.0000 - accuracy: 0.9718 - precision: 0.9828 - recall: 0.9596 - auc: 0.9930 - val_loss: 0.1110 - val_tp: 19.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 1.0000 - val_accuracy: 0.9375 - val_precision: 0.9500 - val_recall: 0.9500 - val_auc: 0.9958\nEpoch 223/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0790 - tp: 286.0000 - fp: 4.0000 - tn: 302.0000 - fn: 11.0000 - accuracy: 0.9751 - precision: 0.9862 - recall: 0.9630 - auc: 0.9964 - val_loss: 0.1146 - val_tp: 19.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 1.0000 - val_accuracy: 0.9375 - val_precision: 0.9500 - val_recall: 0.9500 - val_auc: 0.9958\nEpoch 224/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0867 - tp: 286.0000 - fp: 9.0000 - tn: 297.0000 - fn: 11.0000 - accuracy: 0.9668 - precision: 0.9695 - recall: 0.9630 - auc: 0.9957 - val_loss: 0.1132 - val_tp: 19.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 1.0000 - val_accuracy: 0.9375 - val_precision: 0.9500 - val_recall: 0.9500 - val_auc: 0.9958\nEpoch 225/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0922 - tp: 289.0000 - fp: 9.0000 - tn: 297.0000 - fn: 8.0000 - accuracy: 0.9718 - precision: 0.9698 - recall: 0.9731 - auc: 0.9941 - val_loss: 0.1104 - val_tp: 19.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 1.0000 - val_accuracy: 0.9375 - val_precision: 0.9500 - val_recall: 0.9500 - val_auc: 0.9958\nEpoch 226/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0756 - tp: 290.0000 - fp: 8.0000 - tn: 298.0000 - fn: 7.0000 - accuracy: 0.9751 - precision: 0.9732 - recall: 0.9764 - auc: 0.9957 - val_loss: 0.1054 - val_tp: 19.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 1.0000 - val_accuracy: 0.9375 - val_precision: 0.9500 - val_recall: 0.9500 - val_auc: 0.9958\nEpoch 227/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0710 - tp: 287.0000 - fp: 4.0000 - tn: 302.0000 - fn: 10.0000 - accuracy: 0.9768 - precision: 0.9863 - recall: 0.9663 - auc: 0.9972 - val_loss: 0.0997 - val_tp: 19.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 1.0000 - val_accuracy: 0.9375 - val_precision: 0.9500 - val_recall: 0.9500 - val_auc: 0.9958\nEpoch 228/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0589 - tp: 292.0000 - fp: 3.0000 - tn: 303.0000 - fn: 5.0000 - accuracy: 0.9867 - precision: 0.9898 - recall: 0.9832 - auc: 0.9972 - val_loss: 0.0960 - val_tp: 19.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 1.0000 - val_accuracy: 0.9375 - val_precision: 0.9500 - val_recall: 0.9500 - val_auc: 0.9958\nEpoch 229/400\n1/1 [==============================] - 0s 39ms/step - loss: 0.0686 - tp: 291.0000 - fp: 4.0000 - tn: 302.0000 - fn: 6.0000 - accuracy: 0.9834 - precision: 0.9864 - recall: 0.9798 - auc: 0.9957 - val_loss: 0.0935 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 230/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0774 - tp: 290.0000 - fp: 7.0000 - tn: 299.0000 - fn: 7.0000 - accuracy: 0.9768 - precision: 0.9764 - recall: 0.9764 - auc: 0.9966 - val_loss: 0.0894 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 0.9958\nEpoch 231/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0633 - tp: 292.0000 - fp: 5.0000 - tn: 301.0000 - fn: 5.0000 - accuracy: 0.9834 - precision: 0.9832 - recall: 0.9832 - auc: 0.9988 - val_loss: 0.0858 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 232/400\n","name":"stdout"},{"output_type":"stream","text":"1/1 [==============================] - 0s 24ms/step - loss: 0.0758 - tp: 287.0000 - fp: 6.0000 - tn: 300.0000 - fn: 10.0000 - accuracy: 0.9735 - precision: 0.9795 - recall: 0.9663 - auc: 0.9965 - val_loss: 0.0834 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 233/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.0724 - tp: 288.0000 - fp: 4.0000 - tn: 302.0000 - fn: 9.0000 - accuracy: 0.9784 - precision: 0.9863 - recall: 0.9697 - auc: 0.9966 - val_loss: 0.0821 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 234/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.0537 - tp: 291.0000 - fp: 7.0000 - tn: 299.0000 - fn: 6.0000 - accuracy: 0.9784 - precision: 0.9765 - recall: 0.9798 - auc: 0.9992 - val_loss: 0.0810 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 235/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0855 - tp: 289.0000 - fp: 7.0000 - tn: 299.0000 - fn: 8.0000 - accuracy: 0.9751 - precision: 0.9764 - recall: 0.9731 - auc: 0.9959 - val_loss: 0.0806 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 236/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0836 - tp: 288.0000 - fp: 8.0000 - tn: 298.0000 - fn: 9.0000 - accuracy: 0.9718 - precision: 0.9730 - recall: 0.9697 - auc: 0.9957 - val_loss: 0.0783 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 237/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.0781 - tp: 287.0000 - fp: 4.0000 - tn: 302.0000 - fn: 10.0000 - accuracy: 0.9768 - precision: 0.9863 - recall: 0.9663 - auc: 0.9959 - val_loss: 0.0783 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 238/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.0872 - tp: 288.0000 - fp: 11.0000 - tn: 295.0000 - fn: 9.0000 - accuracy: 0.9668 - precision: 0.9632 - recall: 0.9697 - auc: 0.9947 - val_loss: 0.0780 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 239/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0822 - tp: 289.0000 - fp: 9.0000 - tn: 297.0000 - fn: 8.0000 - accuracy: 0.9718 - precision: 0.9698 - recall: 0.9731 - auc: 0.9964 - val_loss: 0.0777 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 240/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0552 - tp: 289.0000 - fp: 3.0000 - tn: 303.0000 - fn: 8.0000 - accuracy: 0.9818 - precision: 0.9897 - recall: 0.9731 - auc: 0.9990 - val_loss: 0.0816 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 241/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.0802 - tp: 292.0000 - fp: 8.0000 - tn: 298.0000 - fn: 5.0000 - accuracy: 0.9784 - precision: 0.9733 - recall: 0.9832 - auc: 0.9962 - val_loss: 0.0832 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 242/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.0911 - tp: 285.0000 - fp: 6.0000 - tn: 300.0000 - fn: 12.0000 - accuracy: 0.9701 - precision: 0.9794 - recall: 0.9596 - auc: 0.9937 - val_loss: 0.0819 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 243/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0607 - tp: 289.0000 - fp: 2.0000 - tn: 304.0000 - fn: 8.0000 - accuracy: 0.9834 - precision: 0.9931 - recall: 0.9731 - auc: 0.9982 - val_loss: 0.0812 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 244/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0621 - tp: 290.0000 - fp: 3.0000 - tn: 303.0000 - fn: 7.0000 - accuracy: 0.9834 - precision: 0.9898 - recall: 0.9764 - auc: 0.9967 - val_loss: 0.0758 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 245/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0702 - tp: 291.0000 - fp: 6.0000 - tn: 300.0000 - fn: 6.0000 - accuracy: 0.9801 - precision: 0.9798 - recall: 0.9798 - auc: 0.9970 - val_loss: 0.0774 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 246/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0854 - tp: 290.0000 - fp: 11.0000 - tn: 295.0000 - fn: 7.0000 - accuracy: 0.9701 - precision: 0.9635 - recall: 0.9764 - auc: 0.9934 - val_loss: 0.0790 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 247/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0702 - tp: 289.0000 - fp: 6.0000 - tn: 300.0000 - fn: 8.0000 - accuracy: 0.9768 - precision: 0.9797 - recall: 0.9731 - auc: 0.9976 - val_loss: 0.0776 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 248/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0632 - tp: 288.0000 - fp: 7.0000 - tn: 299.0000 - fn: 9.0000 - accuracy: 0.9735 - precision: 0.9763 - recall: 0.9697 - auc: 0.9982 - val_loss: 0.0770 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 249/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.0676 - tp: 286.0000 - fp: 3.0000 - tn: 303.0000 - fn: 11.0000 - accuracy: 0.9768 - precision: 0.9896 - recall: 0.9630 - auc: 0.9953 - val_loss: 0.0781 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 250/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0609 - tp: 292.0000 - fp: 3.0000 - tn: 303.0000 - fn: 5.0000 - accuracy: 0.9867 - precision: 0.9898 - recall: 0.9832 - auc: 0.9974 - val_loss: 0.0808 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 251/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0674 - tp: 288.0000 - fp: 5.0000 - tn: 301.0000 - fn: 9.0000 - accuracy: 0.9768 - precision: 0.9829 - recall: 0.9697 - auc: 0.9976 - val_loss: 0.0861 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 252/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0673 - tp: 291.0000 - fp: 6.0000 - tn: 300.0000 - fn: 6.0000 - accuracy: 0.9801 - precision: 0.9798 - recall: 0.9798 - auc: 0.9970 - val_loss: 0.0870 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 253/400\n","name":"stdout"},{"output_type":"stream","text":"1/1 [==============================] - 0s 27ms/step - loss: 0.0756 - tp: 289.0000 - fp: 7.0000 - tn: 299.0000 - fn: 8.0000 - accuracy: 0.9751 - precision: 0.9764 - recall: 0.9731 - auc: 0.9957 - val_loss: 0.0907 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 254/400\n1/1 [==============================] - 0s 31ms/step - loss: 0.0595 - tp: 288.0000 - fp: 2.0000 - tn: 304.0000 - fn: 9.0000 - accuracy: 0.9818 - precision: 0.9931 - recall: 0.9697 - auc: 0.9975 - val_loss: 0.0923 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 255/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0651 - tp: 290.0000 - fp: 4.0000 - tn: 302.0000 - fn: 7.0000 - accuracy: 0.9818 - precision: 0.9864 - recall: 0.9764 - auc: 0.9966 - val_loss: 0.0874 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 256/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0465 - tp: 292.0000 - fp: 5.0000 - tn: 301.0000 - fn: 5.0000 - accuracy: 0.9834 - precision: 0.9832 - recall: 0.9832 - auc: 0.9994 - val_loss: 0.0859 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 257/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0626 - tp: 291.0000 - fp: 6.0000 - tn: 300.0000 - fn: 6.0000 - accuracy: 0.9801 - precision: 0.9798 - recall: 0.9798 - auc: 0.9981 - val_loss: 0.0850 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\nEpoch 258/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0633 - tp: 287.0000 - fp: 4.0000 - tn: 302.0000 - fn: 10.0000 - accuracy: 0.9768 - precision: 0.9863 - recall: 0.9663 - auc: 0.9978 - val_loss: 0.0856 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 259/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.0713 - tp: 289.0000 - fp: 8.0000 - tn: 298.0000 - fn: 8.0000 - accuracy: 0.9735 - precision: 0.9731 - recall: 0.9731 - auc: 0.9972 - val_loss: 0.0902 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.9000 - val_auc: 1.0000\nEpoch 260/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0626 - tp: 290.0000 - fp: 5.0000 - tn: 301.0000 - fn: 7.0000 - accuracy: 0.9801 - precision: 0.9831 - recall: 0.9764 - auc: 0.9972 - val_loss: 0.0925 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.9000 - val_auc: 1.0000\nEpoch 261/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0609 - tp: 291.0000 - fp: 6.0000 - tn: 300.0000 - fn: 6.0000 - accuracy: 0.9801 - precision: 0.9798 - recall: 0.9798 - auc: 0.9961 - val_loss: 0.0870 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.9000 - val_auc: 1.0000\nEpoch 262/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0581 - tp: 290.0000 - fp: 7.0000 - tn: 299.0000 - fn: 7.0000 - accuracy: 0.9768 - precision: 0.9764 - recall: 0.9764 - auc: 0.9983 - val_loss: 0.0834 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 263/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0592 - tp: 290.0000 - fp: 6.0000 - tn: 300.0000 - fn: 7.0000 - accuracy: 0.9784 - precision: 0.9797 - recall: 0.9764 - auc: 0.9982 - val_loss: 0.0806 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 264/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0644 - tp: 292.0000 - fp: 10.0000 - tn: 296.0000 - fn: 5.0000 - accuracy: 0.9751 - precision: 0.9669 - recall: 0.9832 - auc: 0.9978 - val_loss: 0.0811 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 265/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0460 - tp: 292.0000 - fp: 4.0000 - tn: 302.0000 - fn: 5.0000 - accuracy: 0.9851 - precision: 0.9865 - recall: 0.9832 - auc: 0.9992 - val_loss: 0.0831 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 266/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0429 - tp: 295.0000 - fp: 4.0000 - tn: 302.0000 - fn: 2.0000 - accuracy: 0.9900 - precision: 0.9866 - recall: 0.9933 - auc: 0.9991 - val_loss: 0.0886 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.9000 - val_auc: 1.0000\nEpoch 267/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0522 - tp: 290.0000 - fp: 1.0000 - tn: 305.0000 - fn: 7.0000 - accuracy: 0.9867 - precision: 0.9966 - recall: 0.9764 - auc: 0.9988 - val_loss: 0.1057 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.9000 - val_auc: 1.0000\nEpoch 268/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.0565 - tp: 290.0000 - fp: 6.0000 - tn: 300.0000 - fn: 7.0000 - accuracy: 0.9784 - precision: 0.9797 - recall: 0.9764 - auc: 0.9974 - val_loss: 0.1263 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9958\nEpoch 269/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.0698 - tp: 290.0000 - fp: 2.0000 - tn: 304.0000 - fn: 7.0000 - accuracy: 0.9851 - precision: 0.9932 - recall: 0.9764 - auc: 0.9943 - val_loss: 0.1176 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 270/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0451 - tp: 292.0000 - fp: 3.0000 - tn: 303.0000 - fn: 5.0000 - accuracy: 0.9867 - precision: 0.9898 - recall: 0.9832 - auc: 0.9992 - val_loss: 0.1048 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.9000 - val_auc: 1.0000\nEpoch 271/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.0472 - tp: 292.0000 - fp: 1.0000 - tn: 305.0000 - fn: 5.0000 - accuracy: 0.9900 - precision: 0.9966 - recall: 0.9832 - auc: 0.9979 - val_loss: 0.0949 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.9000 - val_auc: 1.0000\nEpoch 272/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0710 - tp: 289.0000 - fp: 9.0000 - tn: 297.0000 - fn: 8.0000 - accuracy: 0.9718 - precision: 0.9698 - recall: 0.9731 - auc: 0.9967 - val_loss: 0.0817 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 273/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0377 - tp: 291.0000 - fp: 4.0000 - tn: 302.0000 - fn: 6.0000 - accuracy: 0.9834 - precision: 0.9864 - recall: 0.9798 - auc: 0.9996 - val_loss: 0.0805 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 274/400\n","name":"stdout"},{"output_type":"stream","text":"1/1 [==============================] - 0s 25ms/step - loss: 0.0469 - tp: 293.0000 - fp: 3.0000 - tn: 303.0000 - fn: 4.0000 - accuracy: 0.9884 - precision: 0.9899 - recall: 0.9865 - auc: 0.9983 - val_loss: 0.0814 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 0.9958\nEpoch 275/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0650 - tp: 289.0000 - fp: 3.0000 - tn: 303.0000 - fn: 8.0000 - accuracy: 0.9818 - precision: 0.9897 - recall: 0.9731 - auc: 0.9973 - val_loss: 0.0796 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 0.9979\nEpoch 276/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0446 - tp: 291.0000 - fp: 3.0000 - tn: 303.0000 - fn: 6.0000 - accuracy: 0.9851 - precision: 0.9898 - recall: 0.9798 - auc: 0.9991 - val_loss: 0.0788 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 277/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0622 - tp: 290.0000 - fp: 5.0000 - tn: 301.0000 - fn: 7.0000 - accuracy: 0.9801 - precision: 0.9831 - recall: 0.9764 - auc: 0.9977 - val_loss: 0.0870 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.9000 - val_auc: 1.0000\nEpoch 278/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0607 - tp: 290.0000 - fp: 7.0000 - tn: 299.0000 - fn: 7.0000 - accuracy: 0.9768 - precision: 0.9764 - recall: 0.9764 - auc: 0.9982 - val_loss: 0.1110 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 279/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0656 - tp: 289.0000 - fp: 5.0000 - tn: 301.0000 - fn: 8.0000 - accuracy: 0.9784 - precision: 0.9830 - recall: 0.9731 - auc: 0.9977 - val_loss: 0.1466 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9958\nEpoch 280/400\n1/1 [==============================] - 0s 34ms/step - loss: 0.0597 - tp: 292.0000 - fp: 1.0000 - tn: 305.0000 - fn: 5.0000 - accuracy: 0.9900 - precision: 0.9966 - recall: 0.9832 - auc: 0.9954 - val_loss: 0.1752 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 281/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.0580 - tp: 290.0000 - fp: 6.0000 - tn: 300.0000 - fn: 7.0000 - accuracy: 0.9784 - precision: 0.9797 - recall: 0.9764 - auc: 0.9984 - val_loss: 0.1680 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 282/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.0407 - tp: 292.0000 - fp: 2.0000 - tn: 304.0000 - fn: 5.0000 - accuracy: 0.9884 - precision: 0.9932 - recall: 0.9832 - auc: 0.9995 - val_loss: 0.1486 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9958\nEpoch 283/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0547 - tp: 293.0000 - fp: 5.0000 - tn: 301.0000 - fn: 4.0000 - accuracy: 0.9851 - precision: 0.9832 - recall: 0.9865 - auc: 0.9972 - val_loss: 0.1248 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 284/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.0658 - tp: 288.0000 - fp: 4.0000 - tn: 302.0000 - fn: 9.0000 - accuracy: 0.9784 - precision: 0.9863 - recall: 0.9697 - auc: 0.9935 - val_loss: 0.0964 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.9000 - val_auc: 1.0000\nEpoch 285/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0355 - tp: 294.0000 - fp: 1.0000 - tn: 305.0000 - fn: 3.0000 - accuracy: 0.9934 - precision: 0.9966 - recall: 0.9899 - auc: 0.9994 - val_loss: 0.0833 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 286/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.0505 - tp: 292.0000 - fp: 1.0000 - tn: 305.0000 - fn: 5.0000 - accuracy: 0.9900 - precision: 0.9966 - recall: 0.9832 - auc: 0.9964 - val_loss: 0.0834 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 287/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.0600 - tp: 291.0000 - fp: 6.0000 - tn: 300.0000 - fn: 6.0000 - accuracy: 0.9801 - precision: 0.9798 - recall: 0.9798 - auc: 0.9976 - val_loss: 0.0842 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 288/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.0457 - tp: 290.0000 - fp: 0.0000e+00 - tn: 306.0000 - fn: 7.0000 - accuracy: 0.9884 - precision: 1.0000 - recall: 0.9764 - auc: 0.9988 - val_loss: 0.0834 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 289/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.0450 - tp: 292.0000 - fp: 2.0000 - tn: 304.0000 - fn: 5.0000 - accuracy: 0.9884 - precision: 0.9932 - recall: 0.9832 - auc: 0.9975 - val_loss: 0.0830 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 290/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0354 - tp: 294.0000 - fp: 4.0000 - tn: 302.0000 - fn: 3.0000 - accuracy: 0.9884 - precision: 0.9866 - recall: 0.9899 - auc: 0.9996 - val_loss: 0.0894 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.9000 - val_auc: 1.0000\nEpoch 291/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.0563 - tp: 292.0000 - fp: 5.0000 - tn: 301.0000 - fn: 5.0000 - accuracy: 0.9834 - precision: 0.9832 - recall: 0.9832 - auc: 0.9980 - val_loss: 0.1070 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 292/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0452 - tp: 290.0000 - fp: 1.0000 - tn: 305.0000 - fn: 7.0000 - accuracy: 0.9867 - precision: 0.9966 - recall: 0.9764 - auc: 0.9981 - val_loss: 0.1211 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 293/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0405 - tp: 292.0000 - fp: 1.0000 - tn: 305.0000 - fn: 5.0000 - accuracy: 0.9900 - precision: 0.9966 - recall: 0.9832 - auc: 0.9991 - val_loss: 0.1215 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 294/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.0481 - tp: 291.0000 - fp: 7.0000 - tn: 299.0000 - fn: 6.0000 - accuracy: 0.9784 - precision: 0.9765 - recall: 0.9798 - auc: 0.9990 - val_loss: 0.0983 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.9000 - val_auc: 1.0000\nEpoch 295/400\n","name":"stdout"},{"output_type":"stream","text":"1/1 [==============================] - 0s 25ms/step - loss: 0.0426 - tp: 289.0000 - fp: 0.0000e+00 - tn: 306.0000 - fn: 8.0000 - accuracy: 0.9867 - precision: 1.0000 - recall: 0.9731 - auc: 0.9986 - val_loss: 0.0816 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 296/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.0380 - tp: 294.0000 - fp: 3.0000 - tn: 303.0000 - fn: 3.0000 - accuracy: 0.9900 - precision: 0.9899 - recall: 0.9899 - auc: 0.9991 - val_loss: 0.0767 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 297/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0518 - tp: 289.0000 - fp: 2.0000 - tn: 304.0000 - fn: 8.0000 - accuracy: 0.9834 - precision: 0.9931 - recall: 0.9731 - auc: 0.9986 - val_loss: 0.0768 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 298/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.0443 - tp: 290.0000 - fp: 5.0000 - tn: 301.0000 - fn: 7.0000 - accuracy: 0.9801 - precision: 0.9831 - recall: 0.9764 - auc: 0.9990 - val_loss: 0.0838 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 299/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.0368 - tp: 296.0000 - fp: 4.0000 - tn: 302.0000 - fn: 1.0000 - accuracy: 0.9917 - precision: 0.9867 - recall: 0.9966 - auc: 0.9995 - val_loss: 0.0899 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.9000 - val_auc: 1.0000\nEpoch 300/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0681 - tp: 287.0000 - fp: 7.0000 - tn: 299.0000 - fn: 10.0000 - accuracy: 0.9718 - precision: 0.9762 - recall: 0.9663 - auc: 0.9971 - val_loss: 0.0948 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.9000 - val_auc: 1.0000\nEpoch 301/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0457 - tp: 295.0000 - fp: 6.0000 - tn: 300.0000 - fn: 2.0000 - accuracy: 0.9867 - precision: 0.9801 - recall: 0.9933 - auc: 0.9990 - val_loss: 0.0924 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.9000 - val_auc: 1.0000\nEpoch 302/400\n1/1 [==============================] - 0s 38ms/step - loss: 0.0360 - tp: 295.0000 - fp: 2.0000 - tn: 304.0000 - fn: 2.0000 - accuracy: 0.9934 - precision: 0.9933 - recall: 0.9933 - auc: 0.9996 - val_loss: 0.0900 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.9000 - val_auc: 1.0000\nEpoch 303/400\n1/1 [==============================] - 0s 30ms/step - loss: 0.0443 - tp: 293.0000 - fp: 5.0000 - tn: 301.0000 - fn: 4.0000 - accuracy: 0.9851 - precision: 0.9832 - recall: 0.9865 - auc: 0.9988 - val_loss: 0.0853 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 304/400\n1/1 [==============================] - 0s 43ms/step - loss: 0.0442 - tp: 293.0000 - fp: 2.0000 - tn: 304.0000 - fn: 4.0000 - accuracy: 0.9900 - precision: 0.9932 - recall: 0.9865 - auc: 0.9986 - val_loss: 0.0805 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 305/400\n1/1 [==============================] - 0s 29ms/step - loss: 0.0372 - tp: 291.0000 - fp: 0.0000e+00 - tn: 306.0000 - fn: 6.0000 - accuracy: 0.9900 - precision: 1.0000 - recall: 0.9798 - auc: 0.9993 - val_loss: 0.0831 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 0.9958\nEpoch 306/400\n1/1 [==============================] - 0s 29ms/step - loss: 0.0454 - tp: 291.0000 - fp: 7.0000 - tn: 299.0000 - fn: 6.0000 - accuracy: 0.9784 - precision: 0.9765 - recall: 0.9798 - auc: 0.9991 - val_loss: 0.0858 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 0.9958\nEpoch 307/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.0420 - tp: 294.0000 - fp: 5.0000 - tn: 301.0000 - fn: 3.0000 - accuracy: 0.9867 - precision: 0.9833 - recall: 0.9899 - auc: 0.9992 - val_loss: 0.0881 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 0.9958\nEpoch 308/400\n1/1 [==============================] - 0s 30ms/step - loss: 0.0446 - tp: 294.0000 - fp: 5.0000 - tn: 301.0000 - fn: 3.0000 - accuracy: 0.9867 - precision: 0.9833 - recall: 0.9899 - auc: 0.9988 - val_loss: 0.0917 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 309/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.0277 - tp: 295.0000 - fp: 2.0000 - tn: 304.0000 - fn: 2.0000 - accuracy: 0.9934 - precision: 0.9933 - recall: 0.9933 - auc: 0.9998 - val_loss: 0.0985 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.9000 - val_auc: 1.0000\nEpoch 310/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.0502 - tp: 293.0000 - fp: 2.0000 - tn: 304.0000 - fn: 4.0000 - accuracy: 0.9900 - precision: 0.9932 - recall: 0.9865 - auc: 0.9966 - val_loss: 0.1040 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.9000 - val_auc: 1.0000\nEpoch 311/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.0394 - tp: 296.0000 - fp: 5.0000 - tn: 301.0000 - fn: 1.0000 - accuracy: 0.9900 - precision: 0.9834 - recall: 0.9966 - auc: 0.9996 - val_loss: 0.1059 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 312/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.0520 - tp: 293.0000 - fp: 5.0000 - tn: 301.0000 - fn: 4.0000 - accuracy: 0.9851 - precision: 0.9832 - recall: 0.9865 - auc: 0.9985 - val_loss: 0.1055 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 313/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.0527 - tp: 292.0000 - fp: 5.0000 - tn: 301.0000 - fn: 5.0000 - accuracy: 0.9834 - precision: 0.9832 - recall: 0.9832 - auc: 0.9982 - val_loss: 0.1159 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 314/400\n1/1 [==============================] - 0s 29ms/step - loss: 0.0388 - tp: 295.0000 - fp: 5.0000 - tn: 301.0000 - fn: 2.0000 - accuracy: 0.9884 - precision: 0.9833 - recall: 0.9933 - auc: 0.9994 - val_loss: 0.1458 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9937\nEpoch 315/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.0471 - tp: 292.0000 - fp: 3.0000 - tn: 303.0000 - fn: 5.0000 - accuracy: 0.9867 - precision: 0.9898 - recall: 0.9832 - auc: 0.9984 - val_loss: 0.1412 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 316/400\n","name":"stdout"},{"output_type":"stream","text":"1/1 [==============================] - 0s 27ms/step - loss: 0.0269 - tp: 295.0000 - fp: 1.0000 - tn: 305.0000 - fn: 2.0000 - accuracy: 0.9950 - precision: 0.9966 - recall: 0.9933 - auc: 0.9998 - val_loss: 0.1336 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 317/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0285 - tp: 296.0000 - fp: 3.0000 - tn: 303.0000 - fn: 1.0000 - accuracy: 0.9934 - precision: 0.9900 - recall: 0.9966 - auc: 0.9996 - val_loss: 0.1254 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9958\nEpoch 318/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.0291 - tp: 296.0000 - fp: 4.0000 - tn: 302.0000 - fn: 1.0000 - accuracy: 0.9917 - precision: 0.9867 - recall: 0.9966 - auc: 0.9998 - val_loss: 0.1185 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 319/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0418 - tp: 293.0000 - fp: 5.0000 - tn: 301.0000 - fn: 4.0000 - accuracy: 0.9851 - precision: 0.9832 - recall: 0.9865 - auc: 0.9991 - val_loss: 0.1136 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9958\nEpoch 320/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.0576 - tp: 289.0000 - fp: 4.0000 - tn: 302.0000 - fn: 8.0000 - accuracy: 0.9801 - precision: 0.9863 - recall: 0.9731 - auc: 0.9965 - val_loss: 0.1175 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 321/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0415 - tp: 287.0000 - fp: 0.0000e+00 - tn: 306.0000 - fn: 10.0000 - accuracy: 0.9834 - precision: 1.0000 - recall: 0.9663 - auc: 0.9992 - val_loss: 0.1210 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 322/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0293 - tp: 295.0000 - fp: 1.0000 - tn: 305.0000 - fn: 2.0000 - accuracy: 0.9950 - precision: 0.9966 - recall: 0.9933 - auc: 0.9994 - val_loss: 0.1232 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 323/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0359 - tp: 293.0000 - fp: 2.0000 - tn: 304.0000 - fn: 4.0000 - accuracy: 0.9900 - precision: 0.9932 - recall: 0.9865 - auc: 0.9991 - val_loss: 0.1114 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 324/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.0350 - tp: 291.0000 - fp: 2.0000 - tn: 304.0000 - fn: 6.0000 - accuracy: 0.9867 - precision: 0.9932 - recall: 0.9798 - auc: 0.9996 - val_loss: 0.0952 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.9000 - val_auc: 1.0000\nEpoch 325/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.0354 - tp: 294.0000 - fp: 4.0000 - tn: 302.0000 - fn: 3.0000 - accuracy: 0.9884 - precision: 0.9866 - recall: 0.9899 - auc: 0.9994 - val_loss: 0.0856 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 326/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.0544 - tp: 290.0000 - fp: 5.0000 - tn: 301.0000 - fn: 7.0000 - accuracy: 0.9801 - precision: 0.9831 - recall: 0.9764 - auc: 0.9977 - val_loss: 0.0827 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 327/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0388 - tp: 294.0000 - fp: 3.0000 - tn: 303.0000 - fn: 3.0000 - accuracy: 0.9900 - precision: 0.9899 - recall: 0.9899 - auc: 0.9976 - val_loss: 0.0837 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 328/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0359 - tp: 294.0000 - fp: 3.0000 - tn: 303.0000 - fn: 3.0000 - accuracy: 0.9900 - precision: 0.9899 - recall: 0.9899 - auc: 0.9989 - val_loss: 0.0899 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.9000 - val_auc: 1.0000\nEpoch 329/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.0491 - tp: 292.0000 - fp: 3.0000 - tn: 303.0000 - fn: 5.0000 - accuracy: 0.9867 - precision: 0.9898 - recall: 0.9832 - auc: 0.9968 - val_loss: 0.1130 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 330/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.0323 - tp: 293.0000 - fp: 3.0000 - tn: 303.0000 - fn: 4.0000 - accuracy: 0.9884 - precision: 0.9899 - recall: 0.9865 - auc: 0.9996 - val_loss: 0.1549 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 331/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.0501 - tp: 292.0000 - fp: 4.0000 - tn: 302.0000 - fn: 5.0000 - accuracy: 0.9851 - precision: 0.9865 - recall: 0.9832 - auc: 0.9982 - val_loss: 0.1820 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 332/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.0426 - tp: 293.0000 - fp: 1.0000 - tn: 305.0000 - fn: 4.0000 - accuracy: 0.9917 - precision: 0.9966 - recall: 0.9865 - auc: 0.9973 - val_loss: 0.2203 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 333/400\n1/1 [==============================] - 0s 29ms/step - loss: 0.0424 - tp: 294.0000 - fp: 4.0000 - tn: 302.0000 - fn: 3.0000 - accuracy: 0.9884 - precision: 0.9866 - recall: 0.9899 - auc: 0.9970 - val_loss: 0.2195 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 334/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.0389 - tp: 293.0000 - fp: 2.0000 - tn: 304.0000 - fn: 4.0000 - accuracy: 0.9900 - precision: 0.9932 - recall: 0.9865 - auc: 0.9991 - val_loss: 0.2145 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 335/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0467 - tp: 292.0000 - fp: 4.0000 - tn: 302.0000 - fn: 5.0000 - accuracy: 0.9851 - precision: 0.9865 - recall: 0.9832 - auc: 0.9980 - val_loss: 0.2086 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 336/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0402 - tp: 293.0000 - fp: 4.0000 - tn: 302.0000 - fn: 4.0000 - accuracy: 0.9867 - precision: 0.9865 - recall: 0.9865 - auc: 0.9993 - val_loss: 0.2064 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 337/400\n","name":"stdout"},{"output_type":"stream","text":"1/1 [==============================] - 0s 25ms/step - loss: 0.0423 - tp: 292.0000 - fp: 2.0000 - tn: 304.0000 - fn: 5.0000 - accuracy: 0.9884 - precision: 0.9932 - recall: 0.9832 - auc: 0.9989 - val_loss: 0.2043 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 338/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0382 - tp: 292.0000 - fp: 2.0000 - tn: 304.0000 - fn: 5.0000 - accuracy: 0.9884 - precision: 0.9932 - recall: 0.9832 - auc: 0.9991 - val_loss: 0.2036 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 339/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0292 - tp: 293.0000 - fp: 3.0000 - tn: 303.0000 - fn: 4.0000 - accuracy: 0.9884 - precision: 0.9899 - recall: 0.9865 - auc: 0.9997 - val_loss: 0.2035 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 340/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0289 - tp: 296.0000 - fp: 5.0000 - tn: 301.0000 - fn: 1.0000 - accuracy: 0.9900 - precision: 0.9834 - recall: 0.9966 - auc: 0.9998 - val_loss: 0.2058 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 341/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0364 - tp: 292.0000 - fp: 4.0000 - tn: 302.0000 - fn: 5.0000 - accuracy: 0.9851 - precision: 0.9865 - recall: 0.9832 - auc: 0.9992 - val_loss: 0.2086 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 342/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0353 - tp: 294.0000 - fp: 3.0000 - tn: 303.0000 - fn: 3.0000 - accuracy: 0.9900 - precision: 0.9899 - recall: 0.9899 - auc: 0.9990 - val_loss: 0.2207 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 343/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0299 - tp: 295.0000 - fp: 2.0000 - tn: 304.0000 - fn: 2.0000 - accuracy: 0.9934 - precision: 0.9933 - recall: 0.9933 - auc: 0.9995 - val_loss: 0.2353 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 344/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0325 - tp: 294.0000 - fp: 3.0000 - tn: 303.0000 - fn: 3.0000 - accuracy: 0.9900 - precision: 0.9899 - recall: 0.9899 - auc: 0.9990 - val_loss: 0.2469 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 345/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.0333 - tp: 293.0000 - fp: 4.0000 - tn: 302.0000 - fn: 4.0000 - accuracy: 0.9867 - precision: 0.9865 - recall: 0.9865 - auc: 0.9995 - val_loss: 0.2555 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 346/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0440 - tp: 294.0000 - fp: 3.0000 - tn: 303.0000 - fn: 3.0000 - accuracy: 0.9900 - precision: 0.9899 - recall: 0.9899 - auc: 0.9986 - val_loss: 0.2438 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 347/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0382 - tp: 293.0000 - fp: 2.0000 - tn: 304.0000 - fn: 4.0000 - accuracy: 0.9900 - precision: 0.9932 - recall: 0.9865 - auc: 0.9974 - val_loss: 0.2003 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 348/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0311 - tp: 294.0000 - fp: 3.0000 - tn: 303.0000 - fn: 3.0000 - accuracy: 0.9900 - precision: 0.9899 - recall: 0.9899 - auc: 0.9996 - val_loss: 0.1361 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9979\nEpoch 349/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0323 - tp: 294.0000 - fp: 1.0000 - tn: 305.0000 - fn: 3.0000 - accuracy: 0.9934 - precision: 0.9966 - recall: 0.9899 - auc: 0.9989 - val_loss: 0.0739 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 350/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0319 - tp: 293.0000 - fp: 1.0000 - tn: 305.0000 - fn: 4.0000 - accuracy: 0.9917 - precision: 0.9966 - recall: 0.9865 - auc: 0.9987 - val_loss: 0.0788 - val_tp: 19.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 1.0000 - val_accuracy: 0.9375 - val_precision: 0.9500 - val_recall: 0.9500 - val_auc: 0.9958\nEpoch 351/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0452 - tp: 293.0000 - fp: 3.0000 - tn: 303.0000 - fn: 4.0000 - accuracy: 0.9884 - precision: 0.9899 - recall: 0.9865 - auc: 0.9955 - val_loss: 0.0910 - val_tp: 19.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 1.0000 - val_accuracy: 0.9375 - val_precision: 0.9500 - val_recall: 0.9500 - val_auc: 0.9917\nEpoch 352/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0620 - tp: 295.0000 - fp: 8.0000 - tn: 298.0000 - fn: 2.0000 - accuracy: 0.9834 - precision: 0.9736 - recall: 0.9933 - auc: 0.9956 - val_loss: 0.0819 - val_tp: 19.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 1.0000 - val_accuracy: 0.9375 - val_precision: 0.9500 - val_recall: 0.9500 - val_auc: 0.9958\nEpoch 353/400\n1/1 [==============================] - 0s 31ms/step - loss: 0.0468 - tp: 295.0000 - fp: 6.0000 - tn: 300.0000 - fn: 2.0000 - accuracy: 0.9867 - precision: 0.9801 - recall: 0.9933 - auc: 0.9984 - val_loss: 0.0719 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 354/400\n1/1 [==============================] - 0s 36ms/step - loss: 0.0441 - tp: 291.0000 - fp: 3.0000 - tn: 303.0000 - fn: 6.0000 - accuracy: 0.9851 - precision: 0.9898 - recall: 0.9798 - auc: 0.9986 - val_loss: 0.1325 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 355/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.0248 - tp: 293.0000 - fp: 1.0000 - tn: 305.0000 - fn: 4.0000 - accuracy: 0.9917 - precision: 0.9966 - recall: 0.9865 - auc: 0.9999 - val_loss: 0.2132 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 356/400\n1/1 [==============================] - 0s 29ms/step - loss: 0.0358 - tp: 294.0000 - fp: 2.0000 - tn: 304.0000 - fn: 3.0000 - accuracy: 0.9917 - precision: 0.9932 - recall: 0.9899 - auc: 0.9993 - val_loss: 0.2572 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 357/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.0329 - tp: 288.0000 - fp: 0.0000e+00 - tn: 306.0000 - fn: 9.0000 - accuracy: 0.9851 - precision: 1.0000 - recall: 0.9697 - auc: 0.9997 - val_loss: 0.2657 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 358/400\n","name":"stdout"},{"output_type":"stream","text":"1/1 [==============================] - 0s 27ms/step - loss: 0.0419 - tp: 290.0000 - fp: 1.0000 - tn: 305.0000 - fn: 7.0000 - accuracy: 0.9867 - precision: 0.9966 - recall: 0.9764 - auc: 0.9974 - val_loss: 0.2472 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 359/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0275 - tp: 292.0000 - fp: 1.0000 - tn: 305.0000 - fn: 5.0000 - accuracy: 0.9900 - precision: 0.9966 - recall: 0.9832 - auc: 0.9997 - val_loss: 0.2034 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 360/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.0292 - tp: 295.0000 - fp: 0.0000e+00 - tn: 306.0000 - fn: 2.0000 - accuracy: 0.9967 - precision: 1.0000 - recall: 0.9933 - auc: 0.9994 - val_loss: 0.1500 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9958\nEpoch 361/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0370 - tp: 292.0000 - fp: 1.0000 - tn: 305.0000 - fn: 5.0000 - accuracy: 0.9900 - precision: 0.9966 - recall: 0.9832 - auc: 0.9989 - val_loss: 0.1034 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 362/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.0319 - tp: 294.0000 - fp: 1.0000 - tn: 305.0000 - fn: 3.0000 - accuracy: 0.9934 - precision: 0.9966 - recall: 0.9899 - auc: 0.9994 - val_loss: 0.0774 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 363/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.0453 - tp: 295.0000 - fp: 6.0000 - tn: 300.0000 - fn: 2.0000 - accuracy: 0.9867 - precision: 0.9801 - recall: 0.9933 - auc: 0.9983 - val_loss: 0.0666 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 364/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.0423 - tp: 293.0000 - fp: 4.0000 - tn: 302.0000 - fn: 4.0000 - accuracy: 0.9867 - precision: 0.9865 - recall: 0.9865 - auc: 0.9975 - val_loss: 0.0645 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 365/400\n1/1 [==============================] - 0s 28ms/step - loss: 0.0519 - tp: 292.0000 - fp: 5.0000 - tn: 301.0000 - fn: 5.0000 - accuracy: 0.9834 - precision: 0.9832 - recall: 0.9832 - auc: 0.9967 - val_loss: 0.0704 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 366/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.0313 - tp: 294.0000 - fp: 4.0000 - tn: 302.0000 - fn: 3.0000 - accuracy: 0.9884 - precision: 0.9866 - recall: 0.9899 - auc: 0.9995 - val_loss: 0.0830 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 367/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.0359 - tp: 295.0000 - fp: 4.0000 - tn: 302.0000 - fn: 2.0000 - accuracy: 0.9900 - precision: 0.9866 - recall: 0.9933 - auc: 0.9993 - val_loss: 0.1184 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 368/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.0330 - tp: 293.0000 - fp: 2.0000 - tn: 304.0000 - fn: 4.0000 - accuracy: 0.9900 - precision: 0.9932 - recall: 0.9865 - auc: 0.9993 - val_loss: 0.1833 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9958\nEpoch 369/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0352 - tp: 291.0000 - fp: 1.0000 - tn: 305.0000 - fn: 6.0000 - accuracy: 0.9884 - precision: 0.9966 - recall: 0.9798 - auc: 0.9994 - val_loss: 0.2220 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9958\nEpoch 370/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0272 - tp: 295.0000 - fp: 2.0000 - tn: 304.0000 - fn: 2.0000 - accuracy: 0.9934 - precision: 0.9933 - recall: 0.9933 - auc: 0.9996 - val_loss: 0.2396 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9938\nEpoch 371/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0481 - tp: 289.0000 - fp: 1.0000 - tn: 305.0000 - fn: 8.0000 - accuracy: 0.9851 - precision: 0.9966 - recall: 0.9731 - auc: 0.9986 - val_loss: 0.2222 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9958\nEpoch 372/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0281 - tp: 293.0000 - fp: 2.0000 - tn: 304.0000 - fn: 4.0000 - accuracy: 0.9900 - precision: 0.9932 - recall: 0.9865 - auc: 0.9997 - val_loss: 0.1715 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 373/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0280 - tp: 294.0000 - fp: 2.0000 - tn: 304.0000 - fn: 3.0000 - accuracy: 0.9917 - precision: 0.9932 - recall: 0.9899 - auc: 0.9996 - val_loss: 0.1094 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 374/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0272 - tp: 295.0000 - fp: 2.0000 - tn: 304.0000 - fn: 2.0000 - accuracy: 0.9934 - precision: 0.9933 - recall: 0.9933 - auc: 0.9998 - val_loss: 0.0742 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 375/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.0346 - tp: 295.0000 - fp: 2.0000 - tn: 304.0000 - fn: 2.0000 - accuracy: 0.9934 - precision: 0.9933 - recall: 0.9933 - auc: 0.9989 - val_loss: 0.0666 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 376/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.0410 - tp: 294.0000 - fp: 2.0000 - tn: 304.0000 - fn: 3.0000 - accuracy: 0.9917 - precision: 0.9932 - recall: 0.9899 - auc: 0.9973 - val_loss: 0.0715 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 0.9917\nEpoch 377/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.0320 - tp: 295.0000 - fp: 5.0000 - tn: 301.0000 - fn: 2.0000 - accuracy: 0.9884 - precision: 0.9833 - recall: 0.9933 - auc: 0.9995 - val_loss: 0.0711 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 0.9917\nEpoch 378/400\n1/1 [==============================] - 0s 24ms/step - loss: 0.0349 - tp: 293.0000 - fp: 4.0000 - tn: 302.0000 - fn: 4.0000 - accuracy: 0.9867 - precision: 0.9865 - recall: 0.9865 - auc: 0.9994 - val_loss: 0.0658 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 379/400\n","name":"stdout"},{"output_type":"stream","text":"1/1 [==============================] - 0s 27ms/step - loss: 0.0389 - tp: 295.0000 - fp: 5.0000 - tn: 301.0000 - fn: 2.0000 - accuracy: 0.9884 - precision: 0.9833 - recall: 0.9933 - auc: 0.9988 - val_loss: 0.0613 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 380/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0350 - tp: 294.0000 - fp: 3.0000 - tn: 303.0000 - fn: 3.0000 - accuracy: 0.9900 - precision: 0.9899 - recall: 0.9899 - auc: 0.9991 - val_loss: 0.0642 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9500 - val_auc: 1.0000\nEpoch 381/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0402 - tp: 294.0000 - fp: 2.0000 - tn: 304.0000 - fn: 3.0000 - accuracy: 0.9917 - precision: 0.9932 - recall: 0.9899 - auc: 0.9971 - val_loss: 0.1083 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 382/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0232 - tp: 292.0000 - fp: 2.0000 - tn: 304.0000 - fn: 5.0000 - accuracy: 0.9884 - precision: 0.9932 - recall: 0.9832 - auc: 0.9998 - val_loss: 0.1859 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 383/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0413 - tp: 293.0000 - fp: 4.0000 - tn: 302.0000 - fn: 4.0000 - accuracy: 0.9867 - precision: 0.9865 - recall: 0.9865 - auc: 0.9969 - val_loss: 0.2446 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9958\nEpoch 384/400\n1/1 [==============================] - 0s 26ms/step - loss: 0.0295 - tp: 292.0000 - fp: 0.0000e+00 - tn: 306.0000 - fn: 5.0000 - accuracy: 0.9917 - precision: 1.0000 - recall: 0.9832 - auc: 0.9996 - val_loss: 0.2635 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 385/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0302 - tp: 292.0000 - fp: 1.0000 - tn: 305.0000 - fn: 5.0000 - accuracy: 0.9900 - precision: 0.9966 - recall: 0.9832 - auc: 0.9990 - val_loss: 0.2616 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9917\nEpoch 386/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.0363 - tp: 290.0000 - fp: 3.0000 - tn: 303.0000 - fn: 7.0000 - accuracy: 0.9834 - precision: 0.9898 - recall: 0.9764 - auc: 0.9994 - val_loss: 0.2307 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9958\nEpoch 387/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0476 - tp: 293.0000 - fp: 3.0000 - tn: 303.0000 - fn: 4.0000 - accuracy: 0.9884 - precision: 0.9899 - recall: 0.9865 - auc: 0.9969 - val_loss: 0.1816 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9958\nEpoch 388/400\n1/1 [==============================] - 0s 27ms/step - loss: 0.0433 - tp: 294.0000 - fp: 3.0000 - tn: 303.0000 - fn: 3.0000 - accuracy: 0.9900 - precision: 0.9899 - recall: 0.9899 - auc: 0.9975 - val_loss: 0.1303 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 389/400\n1/1 [==============================] - 0s 25ms/step - loss: 0.0429 - tp: 296.0000 - fp: 5.0000 - tn: 301.0000 - fn: 1.0000 - accuracy: 0.9900 - precision: 0.9834 - recall: 0.9966 - auc: 0.9975 - val_loss: 0.1027 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 390/400\n1/1 [==============================] - 0s 41ms/step - loss: 0.0166 - tp: 295.0000 - fp: 1.0000 - tn: 305.0000 - fn: 2.0000 - accuracy: 0.9950 - precision: 0.9966 - recall: 0.9933 - auc: 1.0000 - val_loss: 0.0873 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.9000 - val_auc: 1.0000\nEpoch 391/400\n1/1 [==============================] - 0s 48ms/step - loss: 0.0358 - tp: 294.0000 - fp: 4.0000 - tn: 302.0000 - fn: 3.0000 - accuracy: 0.9884 - precision: 0.9866 - recall: 0.9899 - auc: 0.9994 - val_loss: 0.0833 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.9000 - val_auc: 1.0000\nEpoch 392/400\n1/1 [==============================] - 0s 42ms/step - loss: 0.0380 - tp: 294.0000 - fp: 4.0000 - tn: 302.0000 - fn: 3.0000 - accuracy: 0.9884 - precision: 0.9866 - recall: 0.9899 - auc: 0.9991 - val_loss: 0.0882 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.9000 - val_auc: 1.0000\nEpoch 393/400\n1/1 [==============================] - 0s 41ms/step - loss: 0.0275 - tp: 294.0000 - fp: 3.0000 - tn: 303.0000 - fn: 3.0000 - accuracy: 0.9900 - precision: 0.9899 - recall: 0.9899 - auc: 0.9994 - val_loss: 0.1005 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 394/400\n1/1 [==============================] - 0s 45ms/step - loss: 0.0328 - tp: 295.0000 - fp: 4.0000 - tn: 302.0000 - fn: 2.0000 - accuracy: 0.9900 - precision: 0.9866 - recall: 0.9933 - auc: 0.9995 - val_loss: 0.1339 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 395/400\n1/1 [==============================] - 0s 45ms/step - loss: 0.0305 - tp: 295.0000 - fp: 5.0000 - tn: 301.0000 - fn: 2.0000 - accuracy: 0.9884 - precision: 0.9833 - recall: 0.9933 - auc: 0.9995 - val_loss: 0.1768 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 396/400\n1/1 [==============================] - 0s 37ms/step - loss: 0.0192 - tp: 294.0000 - fp: 1.0000 - tn: 305.0000 - fn: 3.0000 - accuracy: 0.9934 - precision: 0.9966 - recall: 0.9899 - auc: 0.9999 - val_loss: 0.2051 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9979\nEpoch 397/400\n1/1 [==============================] - 0s 36ms/step - loss: 0.0186 - tp: 295.0000 - fp: 0.0000e+00 - tn: 306.0000 - fn: 2.0000 - accuracy: 0.9967 - precision: 1.0000 - recall: 0.9933 - auc: 1.0000 - val_loss: 0.2182 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9958\nEpoch 398/400\n1/1 [==============================] - 0s 35ms/step - loss: 0.0249 - tp: 294.0000 - fp: 1.0000 - tn: 305.0000 - fn: 3.0000 - accuracy: 0.9934 - precision: 0.9966 - recall: 0.9899 - auc: 0.9992 - val_loss: 0.2186 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 0.9979\nEpoch 399/400\n1/1 [==============================] - 0s 35ms/step - loss: 0.0314 - tp: 292.0000 - fp: 1.0000 - tn: 305.0000 - fn: 5.0000 - accuracy: 0.9900 - precision: 0.9966 - recall: 0.9832 - auc: 0.9992 - val_loss: 0.2169 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\nEpoch 400/400\n","name":"stdout"},{"output_type":"stream","text":"1/1 [==============================] - ETA: 0s - loss: 0.0215 - tp: 294.0000 - fp: 2.0000 - tn: 304.0000 - fn: 3.0000 - accuracy: 0.9917 - precision: 0.9932 - recall: 0.9899 - auc: 0.9998\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 37ms/step - loss: 0.0215 - tp: 294.0000 - fp: 2.0000 - tn: 304.0000 - fn: 3.0000 - accuracy: 0.9917 - precision: 0.9932 - recall: 0.9899 - auc: 0.9998 - val_loss: 0.2066 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8500 - val_auc: 1.0000\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate model performance on unseen data\nmodel.evaluate(X_test, y_test, batch_size=batch_size)","execution_count":38,"outputs":[{"output_type":"stream","text":"1/1 [==============================] - 0s 3ms/step - loss: 0.1619 - tp: 32.0000 - fp: 1.0000 - tn: 34.0000 - fn: 4.0000 - accuracy: 0.9296 - precision: 0.9697 - recall: 0.8889 - auc: 0.9825\n","name":"stdout"},{"output_type":"execute_result","execution_count":38,"data":{"text/plain":"[0.161886066198349,\n 32.0,\n 1.0,\n 34.0,\n 4.0,\n 0.9295774698257446,\n 0.9696969985961914,\n 0.8888888955116272,\n 0.982539713382721]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"We finally achieve good results across all metrics. We save the weights of this model into .h5 file "},{"metadata":{"trusted":true},"cell_type":"code","source":"# save the model weights to .h5 file\nmodel.save_weights('trained_weights_400eps_tauc0.98.h5')","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save model\nmodel.save('trained_model_object.h5')","execution_count":40,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}